2023-09-05 17:01:50.329 | INFO     | __main__:main:373 - Namespace(batch_size=2, caption_loss_weight=1.0, checkpoint_dir='checkpoints', contrastive_loss_weight=1.0, dataset='Beijing_captions', dim=512, dim_head=64, epoch_num=6, heads=8, img_dim=1024, img_encoder='vit', log_every_n_steps=100, logging_dir='logs', lr=0.0003, multimodal_depth=6, num_tokens=20000, pretrained_model='/root/laion-mscoco_finetuned_CoCa-ViT-L-14-laion2B-s13B-b90k/open_clip_pytorch_model.bin', seed=132, test_dataset_ratio=0.1, train_dataset_ratio=0.8, unimodal_depth=6, val_dataset_ratio=0.1, weight_decay=0.01)
2023-09-05 17:02:00.998 | INFO     | __main__:main:414 - Start epoch 0
2023-09-05 17:02:01.364 | INFO     | __main__:train_one_epoch:179 - Train Epoch: 0 [ 0/28 (7%)] Data (t): 0.001 Batch (t): 0.356, 5.61992/s, Logit Scale: 100.000 Contrastive_loss: 1.7810 (1.7810) Caption_loss: 2.9964 (2.9964) Loss: 4.7774 (4.7774)
2023-09-05 17:02:01.364 | INFO     | __main__:train_one_epoch:199 - {'train/data_time': 0.0009577274322509766, 'step': 0}
2023-09-05 17:02:01.364 | INFO     | __main__:train_one_epoch:199 - {'train/batch_time': 0.3558769226074219, 'step': 0}
2023-09-05 17:02:01.364 | INFO     | __main__:train_one_epoch:199 - {'train/samples_per_second': 5.619920463924709, 'step': 0}
2023-09-05 17:02:01.364 | INFO     | __main__:train_one_epoch:199 - {'train/scale': 100.0, 'step': 0}
2023-09-05 17:02:01.365 | INFO     | __main__:train_one_epoch:199 - {'train/contrastive_loss': 1.7809691429138184, 'step': 0}
2023-09-05 17:02:01.365 | INFO     | __main__:train_one_epoch:199 - {'train/caption_loss': 2.9964170455932617, 'step': 0}
2023-09-05 17:02:01.365 | INFO     | __main__:train_one_epoch:199 - {'train/loss': 4.77738618850708, 'step': 0}
2023-09-05 17:02:04.578 | INFO     | __main__:evaluate:252 - Eval Epoch: 1 [2 / 4]	Clip Loss: 0.788622	
2023-09-05 17:02:04.578 | INFO     | __main__:evaluate:258 - Generative Loss: 12.559273	
2023-09-05 17:02:04.655 | INFO     | __main__:evaluate:274 - Eval Epoch: 1 image_to_text_mean_rank: 2.5000	image_to_text_median_rank: 2.0000	image_to_text_R@1: 0.2500	image_to_text_R@5: 1.0000	image_to_text_R@10: 1.0000	text_to_image_mean_rank: 2.5000	text_to_image_median_rank: 2.0000	text_to_image_R@1: 0.2500	text_to_image_R@5: 1.0000	text_to_image_R@10: 1.0000	clip_val_loss: 0.7409	epoch: 1.0000	num_samples: 4.0000	val_generative_loss: 6.2796
2023-09-05 17:02:04.656 | INFO     | __main__:evaluate:280 - {'val/image_to_text_mean_rank': 2.5, 'epoch': 1}
2023-09-05 17:02:04.656 | INFO     | __main__:evaluate:280 - {'val/image_to_text_median_rank': 2.0, 'epoch': 1}
2023-09-05 17:02:04.656 | INFO     | __main__:evaluate:280 - {'val/image_to_text_R@1': 0.25, 'epoch': 1}
2023-09-05 17:02:04.656 | INFO     | __main__:evaluate:280 - {'val/image_to_text_R@5': 1.0, 'epoch': 1}
2023-09-05 17:02:04.656 | INFO     | __main__:evaluate:280 - {'val/image_to_text_R@10': 1.0, 'epoch': 1}
2023-09-05 17:02:04.656 | INFO     | __main__:evaluate:280 - {'val/text_to_image_mean_rank': 2.5, 'epoch': 1}
2023-09-05 17:02:04.656 | INFO     | __main__:evaluate:280 - {'val/text_to_image_median_rank': 2.0, 'epoch': 1}
2023-09-05 17:02:04.657 | INFO     | __main__:evaluate:280 - {'val/text_to_image_R@1': 0.25, 'epoch': 1}
2023-09-05 17:02:04.657 | INFO     | __main__:evaluate:280 - {'val/text_to_image_R@5': 1.0, 'epoch': 1}
2023-09-05 17:02:04.657 | INFO     | __main__:evaluate:280 - {'val/text_to_image_R@10': 1.0, 'epoch': 1}
2023-09-05 17:02:04.657 | INFO     | __main__:evaluate:280 - {'val/clip_val_loss': 0.7409343719482422, 'epoch': 1}
2023-09-05 17:02:04.657 | INFO     | __main__:evaluate:280 - {'val/epoch': 1, 'epoch': 1}
2023-09-05 17:02:04.657 | INFO     | __main__:evaluate:280 - {'val/num_samples': 4, 'epoch': 1}
2023-09-05 17:02:04.657 | INFO     | __main__:evaluate:280 - {'val/val_generative_loss': 6.279636383056641, 'epoch': 1}
2023-09-05 17:02:12.302 | INFO     | __main__:main:414 - Start epoch 1
2023-09-05 17:02:15.753 | INFO     | __main__:evaluate:252 - Eval Epoch: 2 [2 / 4]	Clip Loss: 0.792299	
2023-09-05 17:02:15.754 | INFO     | __main__:evaluate:258 - Generative Loss: 13.128888	
2023-09-05 17:02:15.830 | INFO     | __main__:evaluate:274 - Eval Epoch: 2 image_to_text_mean_rank: 2.5000	image_to_text_median_rank: 2.0000	image_to_text_R@1: 0.2500	image_to_text_R@5: 1.0000	image_to_text_R@10: 1.0000	text_to_image_mean_rank: 2.5000	text_to_image_median_rank: 2.0000	text_to_image_R@1: 0.2500	text_to_image_R@5: 1.0000	text_to_image_R@10: 1.0000	clip_val_loss: 0.7655	epoch: 2.0000	num_samples: 4.0000	val_generative_loss: 6.5644
2023-09-05 17:02:15.831 | INFO     | __main__:evaluate:280 - {'val/image_to_text_mean_rank': 2.5, 'epoch': 2}
2023-09-05 17:02:15.831 | INFO     | __main__:evaluate:280 - {'val/image_to_text_median_rank': 2.0, 'epoch': 2}
2023-09-05 17:02:15.831 | INFO     | __main__:evaluate:280 - {'val/image_to_text_R@1': 0.25, 'epoch': 2}
2023-09-05 17:02:15.831 | INFO     | __main__:evaluate:280 - {'val/image_to_text_R@5': 1.0, 'epoch': 2}
2023-09-05 17:02:15.831 | INFO     | __main__:evaluate:280 - {'val/image_to_text_R@10': 1.0, 'epoch': 2}
2023-09-05 17:02:15.831 | INFO     | __main__:evaluate:280 - {'val/text_to_image_mean_rank': 2.5, 'epoch': 2}
2023-09-05 17:02:15.831 | INFO     | __main__:evaluate:280 - {'val/text_to_image_median_rank': 2.0, 'epoch': 2}
2023-09-05 17:02:15.832 | INFO     | __main__:evaluate:280 - {'val/text_to_image_R@1': 0.25, 'epoch': 2}
2023-09-05 17:02:15.832 | INFO     | __main__:evaluate:280 - {'val/text_to_image_R@5': 1.0, 'epoch': 2}
2023-09-05 17:02:15.832 | INFO     | __main__:evaluate:280 - {'val/text_to_image_R@10': 1.0, 'epoch': 2}
2023-09-05 17:02:15.832 | INFO     | __main__:evaluate:280 - {'val/clip_val_loss': 0.7655172348022461, 'epoch': 2}
2023-09-05 17:02:15.832 | INFO     | __main__:evaluate:280 - {'val/epoch': 2, 'epoch': 2}
2023-09-05 17:02:15.832 | INFO     | __main__:evaluate:280 - {'val/num_samples': 4, 'epoch': 2}
2023-09-05 17:02:15.832 | INFO     | __main__:evaluate:280 - {'val/val_generative_loss': 6.564444065093994, 'epoch': 2}
2023-09-05 17:02:15.836 | INFO     | __main__:main:414 - Start epoch 2
2023-09-05 17:02:19.269 | INFO     | __main__:evaluate:252 - Eval Epoch: 3 [2 / 4]	Clip Loss: 0.696738	
2023-09-05 17:02:19.269 | INFO     | __main__:evaluate:258 - Generative Loss: 13.341458	
2023-09-05 17:02:19.346 | INFO     | __main__:evaluate:274 - Eval Epoch: 3 image_to_text_mean_rank: 2.5000	image_to_text_median_rank: 2.0000	image_to_text_R@1: 0.2500	image_to_text_R@5: 1.0000	image_to_text_R@10: 1.0000	text_to_image_mean_rank: 2.5000	text_to_image_median_rank: 2.0000	text_to_image_R@1: 0.2500	text_to_image_R@5: 1.0000	text_to_image_R@10: 1.0000	clip_val_loss: 0.6961	epoch: 3.0000	num_samples: 4.0000	val_generative_loss: 6.6707
2023-09-05 17:02:19.346 | INFO     | __main__:evaluate:280 - {'val/image_to_text_mean_rank': 2.5, 'epoch': 3}
2023-09-05 17:02:19.346 | INFO     | __main__:evaluate:280 - {'val/image_to_text_median_rank': 2.0, 'epoch': 3}
2023-09-05 17:02:19.346 | INFO     | __main__:evaluate:280 - {'val/image_to_text_R@1': 0.25, 'epoch': 3}
2023-09-05 17:02:19.347 | INFO     | __main__:evaluate:280 - {'val/image_to_text_R@5': 1.0, 'epoch': 3}
2023-09-05 17:02:19.347 | INFO     | __main__:evaluate:280 - {'val/image_to_text_R@10': 1.0, 'epoch': 3}
2023-09-05 17:02:19.347 | INFO     | __main__:evaluate:280 - {'val/text_to_image_mean_rank': 2.5, 'epoch': 3}
2023-09-05 17:02:19.347 | INFO     | __main__:evaluate:280 - {'val/text_to_image_median_rank': 2.0, 'epoch': 3}
2023-09-05 17:02:19.347 | INFO     | __main__:evaluate:280 - {'val/text_to_image_R@1': 0.25, 'epoch': 3}
2023-09-05 17:02:19.347 | INFO     | __main__:evaluate:280 - {'val/text_to_image_R@5': 1.0, 'epoch': 3}
2023-09-05 17:02:19.347 | INFO     | __main__:evaluate:280 - {'val/text_to_image_R@10': 1.0, 'epoch': 3}
2023-09-05 17:02:19.347 | INFO     | __main__:evaluate:280 - {'val/clip_val_loss': 0.6960835456848145, 'epoch': 3}
2023-09-05 17:02:19.348 | INFO     | __main__:evaluate:280 - {'val/epoch': 3, 'epoch': 3}
2023-09-05 17:02:19.348 | INFO     | __main__:evaluate:280 - {'val/num_samples': 4, 'epoch': 3}
2023-09-05 17:02:19.348 | INFO     | __main__:evaluate:280 - {'val/val_generative_loss': 6.670729160308838, 'epoch': 3}
2023-09-05 17:02:30.200 | INFO     | __main__:main:414 - Start epoch 3
2023-09-05 17:02:34.007 | INFO     | __main__:evaluate:252 - Eval Epoch: 4 [2 / 4]	Clip Loss: 0.697241	
2023-09-05 17:02:34.008 | INFO     | __main__:evaluate:258 - Generative Loss: 14.038608	
2023-09-05 17:02:34.100 | INFO     | __main__:evaluate:274 - Eval Epoch: 4 image_to_text_mean_rank: 2.5000	image_to_text_median_rank: 2.0000	image_to_text_R@1: 0.2500	image_to_text_R@5: 1.0000	image_to_text_R@10: 1.0000	text_to_image_mean_rank: 2.5000	text_to_image_median_rank: 2.0000	text_to_image_R@1: 0.2500	text_to_image_R@5: 1.0000	text_to_image_R@10: 1.0000	clip_val_loss: 0.6954	epoch: 4.0000	num_samples: 4.0000	val_generative_loss: 7.0193
2023-09-05 17:02:34.101 | INFO     | __main__:evaluate:280 - {'val/image_to_text_mean_rank': 2.5, 'epoch': 4}
2023-09-05 17:02:34.101 | INFO     | __main__:evaluate:280 - {'val/image_to_text_median_rank': 2.0, 'epoch': 4}
2023-09-05 17:02:34.101 | INFO     | __main__:evaluate:280 - {'val/image_to_text_R@1': 0.25, 'epoch': 4}
2023-09-05 17:02:34.101 | INFO     | __main__:evaluate:280 - {'val/image_to_text_R@5': 1.0, 'epoch': 4}
2023-09-05 17:02:34.101 | INFO     | __main__:evaluate:280 - {'val/image_to_text_R@10': 1.0, 'epoch': 4}
2023-09-05 17:02:34.102 | INFO     | __main__:evaluate:280 - {'val/text_to_image_mean_rank': 2.5, 'epoch': 4}
2023-09-05 17:02:34.102 | INFO     | __main__:evaluate:280 - {'val/text_to_image_median_rank': 2.0, 'epoch': 4}
2023-09-05 17:02:34.102 | INFO     | __main__:evaluate:280 - {'val/text_to_image_R@1': 0.25, 'epoch': 4}
2023-09-05 17:02:34.102 | INFO     | __main__:evaluate:280 - {'val/text_to_image_R@5': 1.0, 'epoch': 4}
2023-09-05 17:02:34.102 | INFO     | __main__:evaluate:280 - {'val/text_to_image_R@10': 1.0, 'epoch': 4}
2023-09-05 17:02:34.102 | INFO     | __main__:evaluate:280 - {'val/clip_val_loss': 0.6954030394554138, 'epoch': 4}
2023-09-05 17:02:34.103 | INFO     | __main__:evaluate:280 - {'val/epoch': 4, 'epoch': 4}
2023-09-05 17:02:34.103 | INFO     | __main__:evaluate:280 - {'val/num_samples': 4, 'epoch': 4}
2023-09-05 17:02:34.103 | INFO     | __main__:evaluate:280 - {'val/val_generative_loss': 7.019303798675537, 'epoch': 4}
2023-09-05 17:02:45.290 | INFO     | __main__:main:414 - Start epoch 4
2023-09-05 17:02:49.104 | INFO     | __main__:evaluate:252 - Eval Epoch: 5 [2 / 4]	Clip Loss: 0.693166	
2023-09-05 17:02:49.105 | INFO     | __main__:evaluate:258 - Generative Loss: 14.258410	
2023-09-05 17:02:49.197 | INFO     | __main__:evaluate:274 - Eval Epoch: 5 image_to_text_mean_rank: 2.5000	image_to_text_median_rank: 2.0000	image_to_text_R@1: 0.2500	image_to_text_R@5: 1.0000	image_to_text_R@10: 1.0000	text_to_image_mean_rank: 2.5000	text_to_image_median_rank: 2.0000	text_to_image_R@1: 0.2500	text_to_image_R@5: 1.0000	text_to_image_R@10: 1.0000	clip_val_loss: 0.6930	epoch: 5.0000	num_samples: 4.0000	val_generative_loss: 7.1292
2023-09-05 17:02:49.198 | INFO     | __main__:evaluate:280 - {'val/image_to_text_mean_rank': 2.5, 'epoch': 5}
2023-09-05 17:02:49.198 | INFO     | __main__:evaluate:280 - {'val/image_to_text_median_rank': 2.0, 'epoch': 5}
2023-09-05 17:02:49.198 | INFO     | __main__:evaluate:280 - {'val/image_to_text_R@1': 0.25, 'epoch': 5}
2023-09-05 17:02:49.198 | INFO     | __main__:evaluate:280 - {'val/image_to_text_R@5': 1.0, 'epoch': 5}
2023-09-05 17:02:49.199 | INFO     | __main__:evaluate:280 - {'val/image_to_text_R@10': 1.0, 'epoch': 5}
2023-09-05 17:02:49.199 | INFO     | __main__:evaluate:280 - {'val/text_to_image_mean_rank': 2.5, 'epoch': 5}
2023-09-05 17:02:49.199 | INFO     | __main__:evaluate:280 - {'val/text_to_image_median_rank': 2.0, 'epoch': 5}
2023-09-05 17:02:49.199 | INFO     | __main__:evaluate:280 - {'val/text_to_image_R@1': 0.25, 'epoch': 5}
2023-09-05 17:02:49.199 | INFO     | __main__:evaluate:280 - {'val/text_to_image_R@5': 1.0, 'epoch': 5}
2023-09-05 17:02:49.200 | INFO     | __main__:evaluate:280 - {'val/text_to_image_R@10': 1.0, 'epoch': 5}
2023-09-05 17:02:49.200 | INFO     | __main__:evaluate:280 - {'val/clip_val_loss': 0.6930474638938904, 'epoch': 5}
2023-09-05 17:02:49.200 | INFO     | __main__:evaluate:280 - {'val/epoch': 5, 'epoch': 5}
2023-09-05 17:02:49.200 | INFO     | __main__:evaluate:280 - {'val/num_samples': 4, 'epoch': 5}
2023-09-05 17:02:49.200 | INFO     | __main__:evaluate:280 - {'val/val_generative_loss': 7.129205226898193, 'epoch': 5}
2023-09-05 17:02:57.885 | INFO     | __main__:main:414 - Start epoch 5
2023-09-05 17:03:01.356 | INFO     | __main__:evaluate:252 - Eval Epoch: 6 [2 / 4]	Clip Loss: 0.697312	
2023-09-05 17:03:01.356 | INFO     | __main__:evaluate:258 - Generative Loss: 14.136609	
2023-09-05 17:03:01.433 | INFO     | __main__:evaluate:274 - Eval Epoch: 6 image_to_text_mean_rank: 2.5000	image_to_text_median_rank: 2.0000	image_to_text_R@1: 0.2500	image_to_text_R@5: 1.0000	image_to_text_R@10: 1.0000	text_to_image_mean_rank: 2.5000	text_to_image_median_rank: 2.0000	text_to_image_R@1: 0.2500	text_to_image_R@5: 1.0000	text_to_image_R@10: 1.0000	clip_val_loss: 0.6964	epoch: 6.0000	num_samples: 4.0000	val_generative_loss: 7.0683
2023-09-05 17:03:01.433 | INFO     | __main__:evaluate:280 - {'val/image_to_text_mean_rank': 2.5, 'epoch': 6}
2023-09-05 17:03:01.433 | INFO     | __main__:evaluate:280 - {'val/image_to_text_median_rank': 2.0, 'epoch': 6}
2023-09-05 17:03:01.433 | INFO     | __main__:evaluate:280 - {'val/image_to_text_R@1': 0.25, 'epoch': 6}
2023-09-05 17:03:01.433 | INFO     | __main__:evaluate:280 - {'val/image_to_text_R@5': 1.0, 'epoch': 6}
2023-09-05 17:03:01.433 | INFO     | __main__:evaluate:280 - {'val/image_to_text_R@10': 1.0, 'epoch': 6}
2023-09-05 17:03:01.434 | INFO     | __main__:evaluate:280 - {'val/text_to_image_mean_rank': 2.5, 'epoch': 6}
2023-09-05 17:03:01.434 | INFO     | __main__:evaluate:280 - {'val/text_to_image_median_rank': 2.0, 'epoch': 6}
2023-09-05 17:03:01.434 | INFO     | __main__:evaluate:280 - {'val/text_to_image_R@1': 0.25, 'epoch': 6}
2023-09-05 17:03:01.434 | INFO     | __main__:evaluate:280 - {'val/text_to_image_R@5': 1.0, 'epoch': 6}
2023-09-05 17:03:01.434 | INFO     | __main__:evaluate:280 - {'val/text_to_image_R@10': 1.0, 'epoch': 6}
2023-09-05 17:03:01.434 | INFO     | __main__:evaluate:280 - {'val/clip_val_loss': 0.696428656578064, 'epoch': 6}
2023-09-05 17:03:01.434 | INFO     | __main__:evaluate:280 - {'val/epoch': 6, 'epoch': 6}
2023-09-05 17:03:01.434 | INFO     | __main__:evaluate:280 - {'val/num_samples': 4, 'epoch': 6}
2023-09-05 17:03:01.434 | INFO     | __main__:evaluate:280 - {'val/val_generative_loss': 7.068304538726807, 'epoch': 6}
2023-09-05 17:03:05.725 | INFO     | __main__:inference:331 - Test : [2 / 4]	Clip Loss: 0.691496	
2023-09-05 17:03:05.725 | INFO     | __main__:inference:337 - Generative Loss: 16.946316	
2023-09-05 17:03:05.806 | INFO     | __main__:inference:353 - Test: image_to_text_mean_rank: 2.5000	image_to_text_median_rank: 2.0000	image_to_text_R@1: 0.2500	image_to_text_R@5: 1.0000	image_to_text_R@10: 1.0000	text_to_image_mean_rank: 2.5000	text_to_image_median_rank: 2.0000	text_to_image_R@1: 0.2500	text_to_image_R@5: 1.0000	text_to_image_R@10: 1.0000	clip_test_loss: 0.6923	num_samples: 4.0000	test_generative_loss: 8.4732
2023-09-05 17:03:05.806 | INFO     | __main__:inference:359 - {'test/image_to_text_mean_rank': 2.5}
2023-09-05 17:03:05.806 | INFO     | __main__:inference:359 - {'test/image_to_text_median_rank': 2.0}
2023-09-05 17:03:05.806 | INFO     | __main__:inference:359 - {'test/image_to_text_R@1': 0.25}
2023-09-05 17:03:05.806 | INFO     | __main__:inference:359 - {'test/image_to_text_R@5': 1.0}
2023-09-05 17:03:05.806 | INFO     | __main__:inference:359 - {'test/image_to_text_R@10': 1.0}
2023-09-05 17:03:05.807 | INFO     | __main__:inference:359 - {'test/text_to_image_mean_rank': 2.5}
2023-09-05 17:03:05.807 | INFO     | __main__:inference:359 - {'test/text_to_image_median_rank': 2.0}
2023-09-05 17:03:05.807 | INFO     | __main__:inference:359 - {'test/text_to_image_R@1': 0.25}
2023-09-05 17:03:05.807 | INFO     | __main__:inference:359 - {'test/text_to_image_R@5': 1.0}
2023-09-05 17:03:05.807 | INFO     | __main__:inference:359 - {'test/text_to_image_R@10': 1.0}
2023-09-05 17:03:05.807 | INFO     | __main__:inference:359 - {'test/clip_test_loss': 0.6923470497131348}
2023-09-05 17:03:05.807 | INFO     | __main__:inference:359 - {'test/num_samples': 4}
2023-09-05 17:03:05.807 | INFO     | __main__:inference:359 - {'test/test_generative_loss': 8.47315788269043}
2023-09-05 17:03:05.808 | INFO     | __main__:main:443 - test metric: {'image_to_text_mean_rank': 2.5, 'image_to_text_median_rank': 2.0, 'image_to_text_R@1': 0.25, 'image_to_text_R@5': 1.0, 'image_to_text_R@10': 1.0, 'text_to_image_mean_rank': 2.5, 'text_to_image_median_rank': 2.0, 'text_to_image_R@1': 0.25, 'text_to_image_R@5': 1.0, 'text_to_image_R@10': 1.0, 'clip_test_loss': 0.6923470497131348, 'num_samples': 4, 'test_generative_loss': 8.47315788269043}
2023-09-05 17:43:19.140 | INFO     | __main__:main:382 - Namespace(batch_size=2, caption_loss_weight=1.0, checkpoint_dir='checkpoints', contrastive_loss_weight=1.0, dataset='Beijing_captions', dim=512, dim_head=64, epoch_num=6, heads=8, img_dim=1024, img_encoder='vit', log_every_n_steps=100, logging_dir='logs', lr=0.0003, multimodal_depth=6, num_tokens=20000, pretrained_model='/root/laion-mscoco_finetuned_CoCa-ViT-L-14-laion2B-s13B-b90k/open_clip_pytorch_model.bin', seed=132, test_dataset_ratio=0.1, train_dataset_ratio=0.8, unimodal_depth=6, val_dataset_ratio=0.1, weight_decay=0.01)
2023-09-05 17:43:35.456 | INFO     | __main__:main:392 - model parameters: 638450177
2023-09-05 17:43:35.598 | INFO     | __main__:main:398 - train dataset size: 28
2023-09-05 17:43:35.598 | INFO     | __main__:main:399 - val dataset size: 4
2023-09-05 17:43:35.598 | INFO     | __main__:main:400 - test dataset size: 4
2023-09-05 17:43:35.605 | INFO     | __main__:main:423 - Start epoch 0
2023-09-05 17:43:36.138 | INFO     | __main__:train_one_epoch:187 - Train Epoch: 0 [ 0/28 (7%)] Data (t): 0.003 Batch (t): 0.523, 3.82677/s, Logit Scale: 100.000 Contrastive_loss: 1.7806 (1.7806) Caption_loss: 2.9964 (2.9964) Loss: 4.7769 (4.7769)
2023-09-05 17:43:36.138 | INFO     | __main__:train_one_epoch:207 - {'train/data_time': 0.0025882720947265625, 'step': 0}
2023-09-05 17:43:36.139 | INFO     | __main__:train_one_epoch:207 - {'train/batch_time': 0.5226345062255859, 'step': 0}
2023-09-05 17:43:36.139 | INFO     | __main__:train_one_epoch:207 - {'train/samples_per_second': 3.8267660787340656, 'step': 0}
2023-09-05 17:43:36.139 | INFO     | __main__:train_one_epoch:207 - {'train/scale': 100.0, 'step': 0}
2023-09-05 17:43:36.139 | INFO     | __main__:train_one_epoch:207 - {'train/contrastive_loss': 1.7805602550506592, 'step': 0}
2023-09-05 17:43:36.139 | INFO     | __main__:train_one_epoch:207 - {'train/caption_loss': 2.996373414993286, 'step': 0}
2023-09-05 17:43:36.139 | INFO     | __main__:train_one_epoch:207 - {'train/loss': 4.776933670043945, 'step': 0}
2023-09-05 17:43:39.786 | INFO     | __main__:evaluate:260 - Eval Epoch: 1 [2 / 4]	Clip Loss: 0.695325	
2023-09-05 17:43:39.787 | INFO     | __main__:evaluate:266 - Generative Loss: 12.414271	
2023-09-05 17:43:39.894 | INFO     | __main__:evaluate:282 - Eval Epoch: 1 image_to_text_mean_rank: 2.5000	image_to_text_median_rank: 2.0000	image_to_text_R@1: 0.2500	image_to_text_R@5: 1.0000	image_to_text_R@10: 1.0000	text_to_image_mean_rank: 2.5000	text_to_image_median_rank: 2.0000	text_to_image_R@1: 0.2500	text_to_image_R@5: 1.0000	text_to_image_R@10: 1.0000	clip_val_loss: 0.6976	epoch: 1.0000	num_samples: 4.0000	val_generative_loss: 6.2071
2023-09-05 17:43:39.894 | INFO     | __main__:evaluate:288 - {'val/image_to_text_mean_rank': 2.5, 'epoch': 1}
2023-09-05 17:43:39.894 | INFO     | __main__:evaluate:288 - {'val/image_to_text_median_rank': 2.0, 'epoch': 1}
2023-09-05 17:43:39.894 | INFO     | __main__:evaluate:288 - {'val/image_to_text_R@1': 0.25, 'epoch': 1}
2023-09-05 17:43:39.894 | INFO     | __main__:evaluate:288 - {'val/image_to_text_R@5': 1.0, 'epoch': 1}
2023-09-05 17:43:39.895 | INFO     | __main__:evaluate:288 - {'val/image_to_text_R@10': 1.0, 'epoch': 1}
2023-09-05 17:43:39.895 | INFO     | __main__:evaluate:288 - {'val/text_to_image_mean_rank': 2.5, 'epoch': 1}
2023-09-05 17:43:39.895 | INFO     | __main__:evaluate:288 - {'val/text_to_image_median_rank': 2.0, 'epoch': 1}
2023-09-05 17:43:39.895 | INFO     | __main__:evaluate:288 - {'val/text_to_image_R@1': 0.25, 'epoch': 1}
2023-09-05 17:43:39.895 | INFO     | __main__:evaluate:288 - {'val/text_to_image_R@5': 1.0, 'epoch': 1}
2023-09-05 17:43:39.895 | INFO     | __main__:evaluate:288 - {'val/text_to_image_R@10': 1.0, 'epoch': 1}
2023-09-05 17:43:39.895 | INFO     | __main__:evaluate:288 - {'val/clip_val_loss': 0.6975901126861572, 'epoch': 1}
2023-09-05 17:43:39.896 | INFO     | __main__:evaluate:288 - {'val/epoch': 1, 'epoch': 1}
2023-09-05 17:43:39.896 | INFO     | __main__:evaluate:288 - {'val/num_samples': 4, 'epoch': 1}
2023-09-05 17:43:39.896 | INFO     | __main__:evaluate:288 - {'val/val_generative_loss': 6.2071356773376465, 'epoch': 1}
2023-09-05 17:43:49.601 | INFO     | __main__:main:423 - Start epoch 1
2023-09-05 17:43:53.523 | INFO     | __main__:evaluate:260 - Eval Epoch: 2 [2 / 4]	Clip Loss: 0.706215	
2023-09-05 17:43:53.524 | INFO     | __main__:evaluate:266 - Generative Loss: 14.035668	
2023-09-05 17:43:53.612 | INFO     | __main__:evaluate:282 - Eval Epoch: 2 image_to_text_mean_rank: 2.5000	image_to_text_median_rank: 2.0000	image_to_text_R@1: 0.2500	image_to_text_R@5: 1.0000	image_to_text_R@10: 1.0000	text_to_image_mean_rank: 2.2500	text_to_image_median_rank: 2.0000	text_to_image_R@1: 0.2500	text_to_image_R@5: 1.0000	text_to_image_R@10: 1.0000	clip_val_loss: 0.7069	epoch: 2.0000	num_samples: 4.0000	val_generative_loss: 7.0178
2023-09-05 17:43:53.612 | INFO     | __main__:evaluate:288 - {'val/image_to_text_mean_rank': 2.5, 'epoch': 2}
2023-09-05 17:43:53.612 | INFO     | __main__:evaluate:288 - {'val/image_to_text_median_rank': 2.0, 'epoch': 2}
2023-09-05 17:43:53.612 | INFO     | __main__:evaluate:288 - {'val/image_to_text_R@1': 0.25, 'epoch': 2}
2023-09-05 17:43:53.613 | INFO     | __main__:evaluate:288 - {'val/image_to_text_R@5': 1.0, 'epoch': 2}
2023-09-05 17:43:53.613 | INFO     | __main__:evaluate:288 - {'val/image_to_text_R@10': 1.0, 'epoch': 2}
2023-09-05 17:43:53.613 | INFO     | __main__:evaluate:288 - {'val/text_to_image_mean_rank': 2.25, 'epoch': 2}
2023-09-05 17:43:53.613 | INFO     | __main__:evaluate:288 - {'val/text_to_image_median_rank': 2.0, 'epoch': 2}
2023-09-05 17:43:53.613 | INFO     | __main__:evaluate:288 - {'val/text_to_image_R@1': 0.25, 'epoch': 2}
2023-09-05 17:43:53.613 | INFO     | __main__:evaluate:288 - {'val/text_to_image_R@5': 1.0, 'epoch': 2}
2023-09-05 17:43:53.613 | INFO     | __main__:evaluate:288 - {'val/text_to_image_R@10': 1.0, 'epoch': 2}
2023-09-05 17:43:53.613 | INFO     | __main__:evaluate:288 - {'val/clip_val_loss': 0.7068581581115723, 'epoch': 2}
2023-09-05 17:43:53.613 | INFO     | __main__:evaluate:288 - {'val/epoch': 2, 'epoch': 2}
2023-09-05 17:43:53.613 | INFO     | __main__:evaluate:288 - {'val/num_samples': 4, 'epoch': 2}
2023-09-05 17:43:53.614 | INFO     | __main__:evaluate:288 - {'val/val_generative_loss': 7.017834186553955, 'epoch': 2}
2023-09-05 17:43:53.615 | INFO     | __main__:main:423 - Start epoch 2
2023-09-05 17:43:57.504 | INFO     | __main__:evaluate:260 - Eval Epoch: 3 [2 / 4]	Clip Loss: 0.707546	
2023-09-05 17:43:57.505 | INFO     | __main__:evaluate:266 - Generative Loss: 15.064167	
2023-09-05 17:43:57.594 | INFO     | __main__:evaluate:282 - Eval Epoch: 3 image_to_text_mean_rank: 2.5000	image_to_text_median_rank: 2.0000	image_to_text_R@1: 0.2500	image_to_text_R@5: 1.0000	image_to_text_R@10: 1.0000	text_to_image_mean_rank: 2.5000	text_to_image_median_rank: 2.0000	text_to_image_R@1: 0.2500	text_to_image_R@5: 1.0000	text_to_image_R@10: 1.0000	clip_val_loss: 0.6996	epoch: 3.0000	num_samples: 4.0000	val_generative_loss: 7.5321
2023-09-05 17:43:57.594 | INFO     | __main__:evaluate:288 - {'val/image_to_text_mean_rank': 2.5, 'epoch': 3}
2023-09-05 17:43:57.594 | INFO     | __main__:evaluate:288 - {'val/image_to_text_median_rank': 2.0, 'epoch': 3}
2023-09-05 17:43:57.594 | INFO     | __main__:evaluate:288 - {'val/image_to_text_R@1': 0.25, 'epoch': 3}
2023-09-05 17:43:57.594 | INFO     | __main__:evaluate:288 - {'val/image_to_text_R@5': 1.0, 'epoch': 3}
2023-09-05 17:43:57.594 | INFO     | __main__:evaluate:288 - {'val/image_to_text_R@10': 1.0, 'epoch': 3}
2023-09-05 17:43:57.594 | INFO     | __main__:evaluate:288 - {'val/text_to_image_mean_rank': 2.5, 'epoch': 3}
2023-09-05 17:43:57.595 | INFO     | __main__:evaluate:288 - {'val/text_to_image_median_rank': 2.0, 'epoch': 3}
2023-09-05 17:43:57.595 | INFO     | __main__:evaluate:288 - {'val/text_to_image_R@1': 0.25, 'epoch': 3}
2023-09-05 17:43:57.595 | INFO     | __main__:evaluate:288 - {'val/text_to_image_R@5': 1.0, 'epoch': 3}
2023-09-05 17:43:57.595 | INFO     | __main__:evaluate:288 - {'val/text_to_image_R@10': 1.0, 'epoch': 3}
2023-09-05 17:43:57.595 | INFO     | __main__:evaluate:288 - {'val/clip_val_loss': 0.6996469497680664, 'epoch': 3}
2023-09-05 17:43:57.595 | INFO     | __main__:evaluate:288 - {'val/epoch': 3, 'epoch': 3}
2023-09-05 17:43:57.595 | INFO     | __main__:evaluate:288 - {'val/num_samples': 4, 'epoch': 3}
2023-09-05 17:43:57.595 | INFO     | __main__:evaluate:288 - {'val/val_generative_loss': 7.532083511352539, 'epoch': 3}
2023-09-05 17:43:57.596 | INFO     | __main__:main:423 - Start epoch 3
2023-09-05 17:44:01.517 | INFO     | __main__:evaluate:260 - Eval Epoch: 4 [2 / 4]	Clip Loss: 0.699057	
2023-09-05 17:44:01.517 | INFO     | __main__:evaluate:266 - Generative Loss: 16.277431	
2023-09-05 17:44:01.616 | INFO     | __main__:evaluate:282 - Eval Epoch: 4 image_to_text_mean_rank: 2.5000	image_to_text_median_rank: 2.0000	image_to_text_R@1: 0.2500	image_to_text_R@5: 1.0000	image_to_text_R@10: 1.0000	text_to_image_mean_rank: 2.5000	text_to_image_median_rank: 2.0000	text_to_image_R@1: 0.2500	text_to_image_R@5: 1.0000	text_to_image_R@10: 1.0000	clip_val_loss: 0.7055	epoch: 4.0000	num_samples: 4.0000	val_generative_loss: 8.1387
2023-09-05 17:44:01.616 | INFO     | __main__:evaluate:288 - {'val/image_to_text_mean_rank': 2.5, 'epoch': 4}
2023-09-05 17:44:01.616 | INFO     | __main__:evaluate:288 - {'val/image_to_text_median_rank': 2.0, 'epoch': 4}
2023-09-05 17:44:01.616 | INFO     | __main__:evaluate:288 - {'val/image_to_text_R@1': 0.25, 'epoch': 4}
2023-09-05 17:44:01.616 | INFO     | __main__:evaluate:288 - {'val/image_to_text_R@5': 1.0, 'epoch': 4}
2023-09-05 17:44:01.617 | INFO     | __main__:evaluate:288 - {'val/image_to_text_R@10': 1.0, 'epoch': 4}
2023-09-05 17:44:01.617 | INFO     | __main__:evaluate:288 - {'val/text_to_image_mean_rank': 2.5, 'epoch': 4}
2023-09-05 17:44:01.617 | INFO     | __main__:evaluate:288 - {'val/text_to_image_median_rank': 2.0, 'epoch': 4}
2023-09-05 17:44:01.617 | INFO     | __main__:evaluate:288 - {'val/text_to_image_R@1': 0.25, 'epoch': 4}
2023-09-05 17:44:01.617 | INFO     | __main__:evaluate:288 - {'val/text_to_image_R@5': 1.0, 'epoch': 4}
2023-09-05 17:44:01.617 | INFO     | __main__:evaluate:288 - {'val/text_to_image_R@10': 1.0, 'epoch': 4}
2023-09-05 17:44:01.617 | INFO     | __main__:evaluate:288 - {'val/clip_val_loss': 0.7054924368858337, 'epoch': 4}
2023-09-05 17:44:01.617 | INFO     | __main__:evaluate:288 - {'val/epoch': 4, 'epoch': 4}
2023-09-05 17:44:01.617 | INFO     | __main__:evaluate:288 - {'val/num_samples': 4, 'epoch': 4}
2023-09-05 17:44:01.617 | INFO     | __main__:evaluate:288 - {'val/val_generative_loss': 8.138715744018555, 'epoch': 4}
2023-09-05 17:44:01.618 | INFO     | __main__:main:423 - Start epoch 4
2023-09-05 17:44:05.543 | INFO     | __main__:evaluate:260 - Eval Epoch: 5 [2 / 4]	Clip Loss: 0.762120	
2023-09-05 17:44:05.543 | INFO     | __main__:evaluate:266 - Generative Loss: 16.258587	
2023-09-05 17:44:05.632 | INFO     | __main__:evaluate:282 - Eval Epoch: 5 image_to_text_mean_rank: 2.5000	image_to_text_median_rank: 2.0000	image_to_text_R@1: 0.2500	image_to_text_R@5: 1.0000	image_to_text_R@10: 1.0000	text_to_image_mean_rank: 2.5000	text_to_image_median_rank: 2.0000	text_to_image_R@1: 0.2500	text_to_image_R@5: 1.0000	text_to_image_R@10: 1.0000	clip_val_loss: 0.8063	epoch: 5.0000	num_samples: 4.0000	val_generative_loss: 8.1293
2023-09-05 17:44:05.632 | INFO     | __main__:evaluate:288 - {'val/image_to_text_mean_rank': 2.5, 'epoch': 5}
2023-09-05 17:44:05.632 | INFO     | __main__:evaluate:288 - {'val/image_to_text_median_rank': 2.0, 'epoch': 5}
2023-09-05 17:44:05.632 | INFO     | __main__:evaluate:288 - {'val/image_to_text_R@1': 0.25, 'epoch': 5}
2023-09-05 17:44:05.632 | INFO     | __main__:evaluate:288 - {'val/image_to_text_R@5': 1.0, 'epoch': 5}
2023-09-05 17:44:05.632 | INFO     | __main__:evaluate:288 - {'val/image_to_text_R@10': 1.0, 'epoch': 5}
2023-09-05 17:44:05.632 | INFO     | __main__:evaluate:288 - {'val/text_to_image_mean_rank': 2.5, 'epoch': 5}
2023-09-05 17:44:05.632 | INFO     | __main__:evaluate:288 - {'val/text_to_image_median_rank': 2.0, 'epoch': 5}
2023-09-05 17:44:05.633 | INFO     | __main__:evaluate:288 - {'val/text_to_image_R@1': 0.25, 'epoch': 5}
2023-09-05 17:44:05.633 | INFO     | __main__:evaluate:288 - {'val/text_to_image_R@5': 1.0, 'epoch': 5}
2023-09-05 17:44:05.633 | INFO     | __main__:evaluate:288 - {'val/text_to_image_R@10': 1.0, 'epoch': 5}
2023-09-05 17:44:05.633 | INFO     | __main__:evaluate:288 - {'val/clip_val_loss': 0.8062844276428223, 'epoch': 5}
2023-09-05 17:44:05.633 | INFO     | __main__:evaluate:288 - {'val/epoch': 5, 'epoch': 5}
2023-09-05 17:44:05.633 | INFO     | __main__:evaluate:288 - {'val/num_samples': 4, 'epoch': 5}
2023-09-05 17:44:05.633 | INFO     | __main__:evaluate:288 - {'val/val_generative_loss': 8.129293441772461, 'epoch': 5}
2023-09-05 17:44:05.634 | INFO     | __main__:main:423 - Start epoch 5
2023-09-05 17:44:09.517 | INFO     | __main__:evaluate:260 - Eval Epoch: 6 [2 / 4]	Clip Loss: 0.693901	
2023-09-05 17:44:09.518 | INFO     | __main__:evaluate:266 - Generative Loss: 17.237280	
2023-09-05 17:44:09.611 | INFO     | __main__:evaluate:282 - Eval Epoch: 6 image_to_text_mean_rank: 2.5000	image_to_text_median_rank: 2.0000	image_to_text_R@1: 0.2500	image_to_text_R@5: 1.0000	image_to_text_R@10: 1.0000	text_to_image_mean_rank: 2.5000	text_to_image_median_rank: 2.0000	text_to_image_R@1: 0.2500	text_to_image_R@5: 1.0000	text_to_image_R@10: 1.0000	clip_val_loss: 0.6942	epoch: 6.0000	num_samples: 4.0000	val_generative_loss: 8.6186
2023-09-05 17:44:09.612 | INFO     | __main__:evaluate:288 - {'val/image_to_text_mean_rank': 2.5, 'epoch': 6}
2023-09-05 17:44:09.612 | INFO     | __main__:evaluate:288 - {'val/image_to_text_median_rank': 2.0, 'epoch': 6}
2023-09-05 17:44:09.612 | INFO     | __main__:evaluate:288 - {'val/image_to_text_R@1': 0.25, 'epoch': 6}
2023-09-05 17:44:09.612 | INFO     | __main__:evaluate:288 - {'val/image_to_text_R@5': 1.0, 'epoch': 6}
2023-09-05 17:44:09.612 | INFO     | __main__:evaluate:288 - {'val/image_to_text_R@10': 1.0, 'epoch': 6}
2023-09-05 17:44:09.612 | INFO     | __main__:evaluate:288 - {'val/text_to_image_mean_rank': 2.5, 'epoch': 6}
2023-09-05 17:44:09.612 | INFO     | __main__:evaluate:288 - {'val/text_to_image_median_rank': 2.0, 'epoch': 6}
2023-09-05 17:44:09.612 | INFO     | __main__:evaluate:288 - {'val/text_to_image_R@1': 0.25, 'epoch': 6}
2023-09-05 17:44:09.613 | INFO     | __main__:evaluate:288 - {'val/text_to_image_R@5': 1.0, 'epoch': 6}
2023-09-05 17:44:09.613 | INFO     | __main__:evaluate:288 - {'val/text_to_image_R@10': 1.0, 'epoch': 6}
2023-09-05 17:44:09.613 | INFO     | __main__:evaluate:288 - {'val/clip_val_loss': 0.6942057013511658, 'epoch': 6}
2023-09-05 17:44:09.613 | INFO     | __main__:evaluate:288 - {'val/epoch': 6, 'epoch': 6}
2023-09-05 17:44:09.613 | INFO     | __main__:evaluate:288 - {'val/num_samples': 4, 'epoch': 6}
2023-09-05 17:44:09.613 | INFO     | __main__:evaluate:288 - {'val/val_generative_loss': 8.618639945983887, 'epoch': 6}
2023-09-05 17:44:22.295 | INFO     | __main__:inference:339 - Test : [2 / 4]	Clip Loss: 0.693561	
2023-09-05 17:44:22.295 | INFO     | __main__:inference:345 - Generative Loss: 21.115808	
2023-09-05 17:44:22.390 | INFO     | __main__:inference:361 - Test: image_to_text_mean_rank: 2.5000	image_to_text_median_rank: 2.0000	image_to_text_R@1: 0.2500	image_to_text_R@5: 1.0000	image_to_text_R@10: 1.0000	text_to_image_mean_rank: 2.5000	text_to_image_median_rank: 2.0000	text_to_image_R@1: 0.2500	text_to_image_R@5: 1.0000	text_to_image_R@10: 1.0000	clip_test_loss: 0.6936	num_samples: 4.0000	test_generative_loss: 10.5579
2023-09-05 17:44:22.391 | INFO     | __main__:inference:367 - {'test/image_to_text_mean_rank': 2.5}
2023-09-05 17:44:22.391 | INFO     | __main__:inference:367 - {'test/image_to_text_median_rank': 2.0}
2023-09-05 17:44:22.391 | INFO     | __main__:inference:367 - {'test/image_to_text_R@1': 0.25}
2023-09-05 17:44:22.391 | INFO     | __main__:inference:367 - {'test/image_to_text_R@5': 1.0}
2023-09-05 17:44:22.391 | INFO     | __main__:inference:367 - {'test/image_to_text_R@10': 1.0}
2023-09-05 17:44:22.391 | INFO     | __main__:inference:367 - {'test/text_to_image_mean_rank': 2.5}
2023-09-05 17:44:22.391 | INFO     | __main__:inference:367 - {'test/text_to_image_median_rank': 2.0}
2023-09-05 17:44:22.391 | INFO     | __main__:inference:367 - {'test/text_to_image_R@1': 0.25}
2023-09-05 17:44:22.392 | INFO     | __main__:inference:367 - {'test/text_to_image_R@5': 1.0}
2023-09-05 17:44:22.392 | INFO     | __main__:inference:367 - {'test/text_to_image_R@10': 1.0}
2023-09-05 17:44:22.392 | INFO     | __main__:inference:367 - {'test/clip_test_loss': 0.6935547590255737}
2023-09-05 17:44:22.392 | INFO     | __main__:inference:367 - {'test/num_samples': 4}
2023-09-05 17:44:22.392 | INFO     | __main__:inference:367 - {'test/test_generative_loss': 10.557904243469238}
2023-09-05 17:44:22.392 | INFO     | __main__:main:458 - test metric: {'image_to_text_mean_rank': 2.5, 'image_to_text_median_rank': 2.0, 'image_to_text_R@1': 0.25, 'image_to_text_R@5': 1.0, 'image_to_text_R@10': 1.0, 'text_to_image_mean_rank': 2.5, 'text_to_image_median_rank': 2.0, 'text_to_image_R@1': 0.25, 'text_to_image_R@5': 1.0, 'text_to_image_R@10': 1.0, 'clip_test_loss': 0.6935547590255737, 'num_samples': 4, 'test_generative_loss': 10.557904243469238}
2023-09-05 23:12:11.304 | INFO     | __main__:main:468 - Namespace(batch_size=2, caption_loss_weight=1.0, checkpoint_dir='checkpoints', contrastive_loss_weight=1.0, dataset='Beijing_captions', dim=512, dim_head=64, epoch_num=6, heads=8, img_dim=1024, img_encoder='vit', log_every_n_steps=100, logging_dir='logs', lr=0.0003, multimodal_depth=6, num_tokens=20000, pretrained_model='/root/laion-mscoco_finetuned_CoCa-ViT-L-14-laion2B-s13B-b90k/open_clip_pytorch_model.bin', seed=132, test_dataset_ratio=0.1, train_dataset_ratio=0.8, unimodal_depth=6, val_dataset_ratio=0.1, weight_decay=0.01)
2023-09-05 23:12:22.320 | INFO     | __main__:main:477 - model parameters: 638450177
2023-09-05 23:12:22.441 | INFO     | __main__:main:484 - train dataset size: 28
2023-09-05 23:12:22.441 | INFO     | __main__:main:485 - val dataset size: 4
2023-09-05 23:12:22.441 | INFO     | __main__:main:486 - test dataset size: 4
2023-09-05 23:12:22.446 | INFO     | __main__:main:513 - Start epoch 0
2023-09-05 23:12:22.845 | INFO     | __main__:train_one_epoch:265 - Train Epoch: 0 [ 0/28 (7%)] Data (t): 0.001 Batch (t): 0.388, 5.15910/s, Logit Scale: 100.000 Contrastive_loss: 1.7806 (1.7806) Caption_loss: 2.9964 (2.9964) Loss: 4.7769 (4.7769)
2023-09-05 23:12:22.845 | INFO     | __main__:train_one_epoch:285 - {'train/data_time': 0.001294851303100586, 'step': 0}
2023-09-05 23:12:22.845 | INFO     | __main__:train_one_epoch:285 - {'train/batch_time': 0.387664794921875, 'step': 0}
2023-09-05 23:12:22.846 | INFO     | __main__:train_one_epoch:285 - {'train/samples_per_second': 5.159096276470125, 'step': 0}
2023-09-05 23:12:22.846 | INFO     | __main__:train_one_epoch:285 - {'train/scale': 100.0, 'step': 0}
2023-09-05 23:12:22.846 | INFO     | __main__:train_one_epoch:285 - {'train/contrastive_loss': 1.7805602550506592, 'step': 0}
2023-09-05 23:12:22.846 | INFO     | __main__:train_one_epoch:285 - {'train/caption_loss': 2.996373414993286, 'step': 0}
2023-09-05 23:12:22.846 | INFO     | __main__:train_one_epoch:285 - {'train/loss': 4.776933670043945, 'step': 0}
2023-09-05 23:12:26.442 | INFO     | __main__:evaluate:338 - Eval Epoch: 1 [2 / 4]	Clip Loss: 0.695325	
2023-09-05 23:12:26.442 | INFO     | __main__:evaluate:345 - Generative Loss: 12.414271	
2023-09-05 23:12:26.540 | INFO     | __main__:evaluate:367 - Eval Epoch: 1 image_to_text_mean_rank: 2.5000	image_to_text_median_rank: 2.0000	image_to_text_R@1: 0.2500	image_to_text_R@5: 1.0000	image_to_text_R@10: 1.0000	text_to_image_mean_rank: 2.5000	text_to_image_median_rank: 2.0000	text_to_image_R@1: 0.2500	text_to_image_R@5: 1.0000	text_to_image_R@10: 1.0000	clip_val_loss: 0.6976	epoch: 1.0000	num_samples: 4.0000	val_generative_loss: 6.2071
2023-09-05 23:12:26.540 | INFO     | __main__:evaluate:373 - {'val/image_to_text_mean_rank': 2.5, 'epoch': 1}
2023-09-05 23:12:26.540 | INFO     | __main__:evaluate:373 - {'val/image_to_text_median_rank': 2.0, 'epoch': 1}
2023-09-05 23:12:26.541 | INFO     | __main__:evaluate:373 - {'val/image_to_text_R@1': 0.25, 'epoch': 1}
2023-09-05 23:12:26.541 | INFO     | __main__:evaluate:373 - {'val/image_to_text_R@5': 1.0, 'epoch': 1}
2023-09-05 23:12:26.541 | INFO     | __main__:evaluate:373 - {'val/image_to_text_R@10': 1.0, 'epoch': 1}
2023-09-05 23:12:26.541 | INFO     | __main__:evaluate:373 - {'val/text_to_image_mean_rank': 2.5, 'epoch': 1}
2023-09-05 23:12:26.541 | INFO     | __main__:evaluate:373 - {'val/text_to_image_median_rank': 2.0, 'epoch': 1}
2023-09-05 23:12:26.541 | INFO     | __main__:evaluate:373 - {'val/text_to_image_R@1': 0.25, 'epoch': 1}
2023-09-05 23:12:26.542 | INFO     | __main__:evaluate:373 - {'val/text_to_image_R@5': 1.0, 'epoch': 1}
2023-09-05 23:12:26.542 | INFO     | __main__:evaluate:373 - {'val/text_to_image_R@10': 1.0, 'epoch': 1}
2023-09-05 23:12:26.542 | INFO     | __main__:evaluate:373 - {'val/clip_val_loss': 0.6975901126861572, 'epoch': 1}
2023-09-05 23:12:26.542 | INFO     | __main__:evaluate:373 - {'val/epoch': 1, 'epoch': 1}
2023-09-05 23:12:26.542 | INFO     | __main__:evaluate:373 - {'val/num_samples': 4, 'epoch': 1}
2023-09-05 23:12:26.542 | INFO     | __main__:evaluate:373 - {'val/val_generative_loss': 6.2071356773376465, 'epoch': 1}
2023-09-05 23:12:37.158 | INFO     | __main__:main:513 - Start epoch 1
2023-09-05 23:12:41.079 | INFO     | __main__:evaluate:338 - Eval Epoch: 2 [2 / 4]	Clip Loss: 0.706215	
2023-09-05 23:12:41.079 | INFO     | __main__:evaluate:345 - Generative Loss: 14.035668	
2023-09-05 23:12:41.172 | INFO     | __main__:evaluate:367 - Eval Epoch: 2 image_to_text_mean_rank: 2.5000	image_to_text_median_rank: 2.0000	image_to_text_R@1: 0.2500	image_to_text_R@5: 1.0000	image_to_text_R@10: 1.0000	text_to_image_mean_rank: 2.2500	text_to_image_median_rank: 2.0000	text_to_image_R@1: 0.2500	text_to_image_R@5: 1.0000	text_to_image_R@10: 1.0000	clip_val_loss: 0.7069	epoch: 2.0000	num_samples: 4.0000	val_generative_loss: 7.0178
2023-09-05 23:12:41.173 | INFO     | __main__:evaluate:373 - {'val/image_to_text_mean_rank': 2.5, 'epoch': 2}
2023-09-05 23:12:41.173 | INFO     | __main__:evaluate:373 - {'val/image_to_text_median_rank': 2.0, 'epoch': 2}
2023-09-05 23:12:41.173 | INFO     | __main__:evaluate:373 - {'val/image_to_text_R@1': 0.25, 'epoch': 2}
2023-09-05 23:12:41.173 | INFO     | __main__:evaluate:373 - {'val/image_to_text_R@5': 1.0, 'epoch': 2}
2023-09-05 23:12:41.173 | INFO     | __main__:evaluate:373 - {'val/image_to_text_R@10': 1.0, 'epoch': 2}
2023-09-05 23:12:41.173 | INFO     | __main__:evaluate:373 - {'val/text_to_image_mean_rank': 2.25, 'epoch': 2}
2023-09-05 23:12:41.174 | INFO     | __main__:evaluate:373 - {'val/text_to_image_median_rank': 2.0, 'epoch': 2}
2023-09-05 23:12:41.174 | INFO     | __main__:evaluate:373 - {'val/text_to_image_R@1': 0.25, 'epoch': 2}
2023-09-05 23:12:41.174 | INFO     | __main__:evaluate:373 - {'val/text_to_image_R@5': 1.0, 'epoch': 2}
2023-09-05 23:12:41.174 | INFO     | __main__:evaluate:373 - {'val/text_to_image_R@10': 1.0, 'epoch': 2}
2023-09-05 23:12:41.174 | INFO     | __main__:evaluate:373 - {'val/clip_val_loss': 0.7068581581115723, 'epoch': 2}
2023-09-05 23:12:41.174 | INFO     | __main__:evaluate:373 - {'val/epoch': 2, 'epoch': 2}
2023-09-05 23:12:41.174 | INFO     | __main__:evaluate:373 - {'val/num_samples': 4, 'epoch': 2}
2023-09-05 23:12:41.174 | INFO     | __main__:evaluate:373 - {'val/val_generative_loss': 7.017834186553955, 'epoch': 2}
2023-09-05 23:12:41.176 | INFO     | __main__:main:513 - Start epoch 2
2023-09-05 23:12:45.041 | INFO     | __main__:evaluate:338 - Eval Epoch: 3 [2 / 4]	Clip Loss: 0.707546	
2023-09-05 23:12:45.041 | INFO     | __main__:evaluate:345 - Generative Loss: 15.064167	
2023-09-05 23:12:45.134 | INFO     | __main__:evaluate:367 - Eval Epoch: 3 image_to_text_mean_rank: 2.5000	image_to_text_median_rank: 2.0000	image_to_text_R@1: 0.2500	image_to_text_R@5: 1.0000	image_to_text_R@10: 1.0000	text_to_image_mean_rank: 2.5000	text_to_image_median_rank: 2.0000	text_to_image_R@1: 0.2500	text_to_image_R@5: 1.0000	text_to_image_R@10: 1.0000	clip_val_loss: 0.6996	epoch: 3.0000	num_samples: 4.0000	val_generative_loss: 7.5321
2023-09-05 23:12:45.134 | INFO     | __main__:evaluate:373 - {'val/image_to_text_mean_rank': 2.5, 'epoch': 3}
2023-09-05 23:12:45.134 | INFO     | __main__:evaluate:373 - {'val/image_to_text_median_rank': 2.0, 'epoch': 3}
2023-09-05 23:12:45.134 | INFO     | __main__:evaluate:373 - {'val/image_to_text_R@1': 0.25, 'epoch': 3}
2023-09-05 23:12:45.134 | INFO     | __main__:evaluate:373 - {'val/image_to_text_R@5': 1.0, 'epoch': 3}
2023-09-05 23:12:45.134 | INFO     | __main__:evaluate:373 - {'val/image_to_text_R@10': 1.0, 'epoch': 3}
2023-09-05 23:12:45.134 | INFO     | __main__:evaluate:373 - {'val/text_to_image_mean_rank': 2.5, 'epoch': 3}
2023-09-05 23:12:45.134 | INFO     | __main__:evaluate:373 - {'val/text_to_image_median_rank': 2.0, 'epoch': 3}
2023-09-05 23:12:45.134 | INFO     | __main__:evaluate:373 - {'val/text_to_image_R@1': 0.25, 'epoch': 3}
2023-09-05 23:12:45.135 | INFO     | __main__:evaluate:373 - {'val/text_to_image_R@5': 1.0, 'epoch': 3}
2023-09-05 23:12:45.135 | INFO     | __main__:evaluate:373 - {'val/text_to_image_R@10': 1.0, 'epoch': 3}
2023-09-05 23:12:45.135 | INFO     | __main__:evaluate:373 - {'val/clip_val_loss': 0.6996469497680664, 'epoch': 3}
2023-09-05 23:12:45.135 | INFO     | __main__:evaluate:373 - {'val/epoch': 3, 'epoch': 3}
2023-09-05 23:12:45.135 | INFO     | __main__:evaluate:373 - {'val/num_samples': 4, 'epoch': 3}
2023-09-05 23:12:45.135 | INFO     | __main__:evaluate:373 - {'val/val_generative_loss': 7.532083511352539, 'epoch': 3}
2023-09-05 23:12:45.136 | INFO     | __main__:main:513 - Start epoch 3
2023-09-05 23:12:49.019 | INFO     | __main__:evaluate:338 - Eval Epoch: 4 [2 / 4]	Clip Loss: 0.699057	
2023-09-05 23:12:49.019 | INFO     | __main__:evaluate:345 - Generative Loss: 16.277431	
2023-09-05 23:12:49.117 | INFO     | __main__:evaluate:367 - Eval Epoch: 4 image_to_text_mean_rank: 2.5000	image_to_text_median_rank: 2.0000	image_to_text_R@1: 0.2500	image_to_text_R@5: 1.0000	image_to_text_R@10: 1.0000	text_to_image_mean_rank: 2.5000	text_to_image_median_rank: 2.0000	text_to_image_R@1: 0.2500	text_to_image_R@5: 1.0000	text_to_image_R@10: 1.0000	clip_val_loss: 0.7055	epoch: 4.0000	num_samples: 4.0000	val_generative_loss: 8.1387
2023-09-05 23:12:49.117 | INFO     | __main__:evaluate:373 - {'val/image_to_text_mean_rank': 2.5, 'epoch': 4}
2023-09-05 23:12:49.118 | INFO     | __main__:evaluate:373 - {'val/image_to_text_median_rank': 2.0, 'epoch': 4}
2023-09-05 23:12:49.118 | INFO     | __main__:evaluate:373 - {'val/image_to_text_R@1': 0.25, 'epoch': 4}
2023-09-05 23:12:49.118 | INFO     | __main__:evaluate:373 - {'val/image_to_text_R@5': 1.0, 'epoch': 4}
2023-09-05 23:12:49.118 | INFO     | __main__:evaluate:373 - {'val/image_to_text_R@10': 1.0, 'epoch': 4}
2023-09-05 23:12:49.118 | INFO     | __main__:evaluate:373 - {'val/text_to_image_mean_rank': 2.5, 'epoch': 4}
2023-09-05 23:12:49.118 | INFO     | __main__:evaluate:373 - {'val/text_to_image_median_rank': 2.0, 'epoch': 4}
2023-09-05 23:12:49.118 | INFO     | __main__:evaluate:373 - {'val/text_to_image_R@1': 0.25, 'epoch': 4}
2023-09-05 23:12:49.118 | INFO     | __main__:evaluate:373 - {'val/text_to_image_R@5': 1.0, 'epoch': 4}
2023-09-05 23:12:49.118 | INFO     | __main__:evaluate:373 - {'val/text_to_image_R@10': 1.0, 'epoch': 4}
2023-09-05 23:12:49.118 | INFO     | __main__:evaluate:373 - {'val/clip_val_loss': 0.7054924368858337, 'epoch': 4}
2023-09-05 23:12:49.119 | INFO     | __main__:evaluate:373 - {'val/epoch': 4, 'epoch': 4}
2023-09-05 23:12:49.119 | INFO     | __main__:evaluate:373 - {'val/num_samples': 4, 'epoch': 4}
2023-09-05 23:12:49.119 | INFO     | __main__:evaluate:373 - {'val/val_generative_loss': 8.138715744018555, 'epoch': 4}
2023-09-05 23:12:49.120 | INFO     | __main__:main:513 - Start epoch 4
2023-09-05 23:12:53.029 | INFO     | __main__:evaluate:338 - Eval Epoch: 5 [2 / 4]	Clip Loss: 0.762120	
2023-09-05 23:12:53.029 | INFO     | __main__:evaluate:345 - Generative Loss: 16.258587	
2023-09-05 23:12:53.117 | INFO     | __main__:evaluate:367 - Eval Epoch: 5 image_to_text_mean_rank: 2.5000	image_to_text_median_rank: 2.0000	image_to_text_R@1: 0.2500	image_to_text_R@5: 1.0000	image_to_text_R@10: 1.0000	text_to_image_mean_rank: 2.5000	text_to_image_median_rank: 2.0000	text_to_image_R@1: 0.2500	text_to_image_R@5: 1.0000	text_to_image_R@10: 1.0000	clip_val_loss: 0.8063	epoch: 5.0000	num_samples: 4.0000	val_generative_loss: 8.1293
2023-09-05 23:12:53.118 | INFO     | __main__:evaluate:373 - {'val/image_to_text_mean_rank': 2.5, 'epoch': 5}
2023-09-05 23:12:53.118 | INFO     | __main__:evaluate:373 - {'val/image_to_text_median_rank': 2.0, 'epoch': 5}
2023-09-05 23:12:53.118 | INFO     | __main__:evaluate:373 - {'val/image_to_text_R@1': 0.25, 'epoch': 5}
2023-09-05 23:12:53.118 | INFO     | __main__:evaluate:373 - {'val/image_to_text_R@5': 1.0, 'epoch': 5}
2023-09-05 23:12:53.118 | INFO     | __main__:evaluate:373 - {'val/image_to_text_R@10': 1.0, 'epoch': 5}
2023-09-05 23:12:53.118 | INFO     | __main__:evaluate:373 - {'val/text_to_image_mean_rank': 2.5, 'epoch': 5}
2023-09-05 23:12:53.118 | INFO     | __main__:evaluate:373 - {'val/text_to_image_median_rank': 2.0, 'epoch': 5}
2023-09-05 23:12:53.118 | INFO     | __main__:evaluate:373 - {'val/text_to_image_R@1': 0.25, 'epoch': 5}
2023-09-05 23:12:53.118 | INFO     | __main__:evaluate:373 - {'val/text_to_image_R@5': 1.0, 'epoch': 5}
2023-09-05 23:12:53.119 | INFO     | __main__:evaluate:373 - {'val/text_to_image_R@10': 1.0, 'epoch': 5}
2023-09-05 23:12:53.119 | INFO     | __main__:evaluate:373 - {'val/clip_val_loss': 0.8062844276428223, 'epoch': 5}
2023-09-05 23:12:53.119 | INFO     | __main__:evaluate:373 - {'val/epoch': 5, 'epoch': 5}
2023-09-05 23:12:53.119 | INFO     | __main__:evaluate:373 - {'val/num_samples': 4, 'epoch': 5}
2023-09-05 23:12:53.119 | INFO     | __main__:evaluate:373 - {'val/val_generative_loss': 8.129293441772461, 'epoch': 5}
2023-09-05 23:12:53.120 | INFO     | __main__:main:513 - Start epoch 5
2023-09-05 23:12:57.007 | INFO     | __main__:evaluate:338 - Eval Epoch: 6 [2 / 4]	Clip Loss: 0.693901	
2023-09-05 23:12:57.007 | INFO     | __main__:evaluate:345 - Generative Loss: 17.237280	
2023-09-05 23:12:57.096 | INFO     | __main__:evaluate:367 - Eval Epoch: 6 image_to_text_mean_rank: 2.5000	image_to_text_median_rank: 2.0000	image_to_text_R@1: 0.2500	image_to_text_R@5: 1.0000	image_to_text_R@10: 1.0000	text_to_image_mean_rank: 2.5000	text_to_image_median_rank: 2.0000	text_to_image_R@1: 0.2500	text_to_image_R@5: 1.0000	text_to_image_R@10: 1.0000	clip_val_loss: 0.6942	epoch: 6.0000	num_samples: 4.0000	val_generative_loss: 8.6186
2023-09-05 23:12:57.096 | INFO     | __main__:evaluate:373 - {'val/image_to_text_mean_rank': 2.5, 'epoch': 6}
2023-09-05 23:12:57.096 | INFO     | __main__:evaluate:373 - {'val/image_to_text_median_rank': 2.0, 'epoch': 6}
2023-09-05 23:12:57.096 | INFO     | __main__:evaluate:373 - {'val/image_to_text_R@1': 0.25, 'epoch': 6}
2023-09-05 23:12:57.096 | INFO     | __main__:evaluate:373 - {'val/image_to_text_R@5': 1.0, 'epoch': 6}
2023-09-05 23:12:57.096 | INFO     | __main__:evaluate:373 - {'val/image_to_text_R@10': 1.0, 'epoch': 6}
2023-09-05 23:12:57.096 | INFO     | __main__:evaluate:373 - {'val/text_to_image_mean_rank': 2.5, 'epoch': 6}
2023-09-05 23:12:57.096 | INFO     | __main__:evaluate:373 - {'val/text_to_image_median_rank': 2.0, 'epoch': 6}
2023-09-05 23:12:57.097 | INFO     | __main__:evaluate:373 - {'val/text_to_image_R@1': 0.25, 'epoch': 6}
2023-09-05 23:12:57.097 | INFO     | __main__:evaluate:373 - {'val/text_to_image_R@5': 1.0, 'epoch': 6}
2023-09-05 23:12:57.097 | INFO     | __main__:evaluate:373 - {'val/text_to_image_R@10': 1.0, 'epoch': 6}
2023-09-05 23:12:57.097 | INFO     | __main__:evaluate:373 - {'val/clip_val_loss': 0.6942057013511658, 'epoch': 6}
2023-09-05 23:12:57.097 | INFO     | __main__:evaluate:373 - {'val/epoch': 6, 'epoch': 6}
2023-09-05 23:12:57.097 | INFO     | __main__:evaluate:373 - {'val/num_samples': 4, 'epoch': 6}
2023-09-05 23:12:57.097 | INFO     | __main__:evaluate:373 - {'val/val_generative_loss': 8.618639945983887, 'epoch': 6}
2023-09-05 23:13:09.878 | INFO     | __main__:inference:424 - Test : [2 / 4]	Clip Loss: 0.693561	
2023-09-05 23:13:09.879 | INFO     | __main__:inference:431 - Generative Loss: 21.115808	
2023-09-05 23:13:09.979 | INFO     | __main__:inference:448 - Test: image_to_text_mean_rank: 2.5000	image_to_text_median_rank: 2.0000	image_to_text_R@1: 0.2500	image_to_text_R@5: 1.0000	image_to_text_R@10: 1.0000	text_to_image_mean_rank: 2.5000	text_to_image_median_rank: 2.0000	text_to_image_R@1: 0.2500	text_to_image_R@5: 1.0000	text_to_image_R@10: 1.0000	clip_test_loss: 0.6936	num_samples: 4.0000	test_generative_loss: 10.5579
2023-09-05 23:13:09.979 | INFO     | __main__:inference:453 - {'test/image_to_text_mean_rank': 2.5}
2023-09-05 23:13:09.979 | INFO     | __main__:inference:453 - {'test/image_to_text_median_rank': 2.0}
2023-09-05 23:13:09.979 | INFO     | __main__:inference:453 - {'test/image_to_text_R@1': 0.25}
2023-09-05 23:13:09.979 | INFO     | __main__:inference:453 - {'test/image_to_text_R@5': 1.0}
2023-09-05 23:13:09.979 | INFO     | __main__:inference:453 - {'test/image_to_text_R@10': 1.0}
2023-09-05 23:13:09.979 | INFO     | __main__:inference:453 - {'test/text_to_image_mean_rank': 2.5}
2023-09-05 23:13:09.979 | INFO     | __main__:inference:453 - {'test/text_to_image_median_rank': 2.0}
2023-09-05 23:13:09.979 | INFO     | __main__:inference:453 - {'test/text_to_image_R@1': 0.25}
2023-09-05 23:13:09.980 | INFO     | __main__:inference:453 - {'test/text_to_image_R@5': 1.0}
2023-09-05 23:13:09.980 | INFO     | __main__:inference:453 - {'test/text_to_image_R@10': 1.0}
2023-09-05 23:13:09.980 | INFO     | __main__:inference:453 - {'test/clip_test_loss': 0.6935547590255737}
2023-09-05 23:13:09.980 | INFO     | __main__:inference:453 - {'test/num_samples': 4}
2023-09-05 23:13:09.980 | INFO     | __main__:inference:453 - {'test/test_generative_loss': 10.557904243469238}
2023-09-05 23:13:09.980 | INFO     | __main__:main:550 - test metric: {'image_to_text_mean_rank': 2.5, 'image_to_text_median_rank': 2.0, 'image_to_text_R@1': 0.25, 'image_to_text_R@5': 1.0, 'image_to_text_R@10': 1.0, 'text_to_image_mean_rank': 2.5, 'text_to_image_median_rank': 2.0, 'text_to_image_R@1': 0.25, 'text_to_image_R@5': 1.0, 'text_to_image_R@10': 1.0, 'clip_test_loss': 0.6935547590255737, 'num_samples': 4, 'test_generative_loss': 10.557904243469238}
2023-09-06 14:24:22.425 | INFO     | __main__:main:468 - Namespace(batch_size=2, caption_loss_weight=1.0, checkpoint_dir='checkpoints', contrastive_loss_weight=1.0, dataset='Beijing_captions', dim=512, dim_head=64, epoch_num=6, heads=8, img_dim=1024, img_encoder='vit', log_every_n_steps=100, logging_dir='logs', lr=0.0003, multimodal_depth=6, num_tokens=20000, pretrained_model='/root/laion-mscoco_finetuned_CoCa-ViT-L-14-laion2B-s13B-b90k/open_clip_pytorch_model.bin', seed=132, test_dataset_ratio=0.1, train_dataset_ratio=0.8, unimodal_depth=6, val_dataset_ratio=0.1, weight_decay=0.01)
2023-09-06 14:24:32.977 | INFO     | __main__:main:477 - model parameters: 638450177
2023-09-06 14:24:33.093 | INFO     | __main__:main:484 - train dataset size: 28
2023-09-06 14:24:33.093 | INFO     | __main__:main:485 - val dataset size: 4
2023-09-06 14:24:33.094 | INFO     | __main__:main:486 - test dataset size: 4
2023-09-06 14:24:33.099 | INFO     | __main__:main:513 - Start epoch 0
2023-09-06 14:24:33.502 | INFO     | __main__:train_one_epoch:265 - Train Epoch: 0 [ 0/28 (7%)] Data (t): 0.003 Batch (t): 0.392, 5.09911/s, Logit Scale: 100.000 Contrastive_loss: 1.7806 (1.7806) Caption_loss: 2.9964 (2.9964) Loss: 4.7769 (4.7769)
2023-09-06 14:24:33.503 | INFO     | __main__:train_one_epoch:285 - {'train/data_time': 0.002814769744873047, 'step': 0}
2023-09-06 14:24:33.503 | INFO     | __main__:train_one_epoch:285 - {'train/batch_time': 0.3922250270843506, 'step': 0}
2023-09-06 14:24:33.503 | INFO     | __main__:train_one_epoch:285 - {'train/samples_per_second': 5.099113676827886, 'step': 0}
2023-09-06 14:24:33.503 | INFO     | __main__:train_one_epoch:285 - {'train/scale': 100.0, 'step': 0}
2023-09-06 14:24:33.503 | INFO     | __main__:train_one_epoch:285 - {'train/contrastive_loss': 1.7805602550506592, 'step': 0}
2023-09-06 14:24:33.503 | INFO     | __main__:train_one_epoch:285 - {'train/caption_loss': 2.996373414993286, 'step': 0}
2023-09-06 14:24:33.503 | INFO     | __main__:train_one_epoch:285 - {'train/loss': 4.776933670043945, 'step': 0}
2023-09-06 14:24:37.114 | INFO     | __main__:evaluate:338 - Eval Epoch: 1 [2 / 4]	Clip Loss: 0.695325	
2023-09-06 14:24:37.115 | INFO     | __main__:evaluate:345 - Generative Loss: 12.414271	
2023-09-06 14:24:37.215 | INFO     | __main__:evaluate:367 - Eval Epoch: 1 image_to_text_mean_rank: 2.5000	image_to_text_median_rank: 2.0000	image_to_text_R@1: 0.2500	image_to_text_R@5: 1.0000	image_to_text_R@10: 1.0000	text_to_image_mean_rank: 2.5000	text_to_image_median_rank: 2.0000	text_to_image_R@1: 0.2500	text_to_image_R@5: 1.0000	text_to_image_R@10: 1.0000	clip_val_loss: 0.6976	epoch: 1.0000	num_samples: 4.0000	val_generative_loss: 6.2071
2023-09-06 14:24:37.215 | INFO     | __main__:evaluate:373 - {'val/image_to_text_mean_rank': 2.5, 'epoch': 1}
2023-09-06 14:24:37.216 | INFO     | __main__:evaluate:373 - {'val/image_to_text_median_rank': 2.0, 'epoch': 1}
2023-09-06 14:24:37.216 | INFO     | __main__:evaluate:373 - {'val/image_to_text_R@1': 0.25, 'epoch': 1}
2023-09-06 14:24:37.216 | INFO     | __main__:evaluate:373 - {'val/image_to_text_R@5': 1.0, 'epoch': 1}
2023-09-06 14:24:37.216 | INFO     | __main__:evaluate:373 - {'val/image_to_text_R@10': 1.0, 'epoch': 1}
2023-09-06 14:24:37.216 | INFO     | __main__:evaluate:373 - {'val/text_to_image_mean_rank': 2.5, 'epoch': 1}
2023-09-06 14:24:37.216 | INFO     | __main__:evaluate:373 - {'val/text_to_image_median_rank': 2.0, 'epoch': 1}
2023-09-06 14:24:37.216 | INFO     | __main__:evaluate:373 - {'val/text_to_image_R@1': 0.25, 'epoch': 1}
2023-09-06 14:24:37.217 | INFO     | __main__:evaluate:373 - {'val/text_to_image_R@5': 1.0, 'epoch': 1}
2023-09-06 14:24:37.217 | INFO     | __main__:evaluate:373 - {'val/text_to_image_R@10': 1.0, 'epoch': 1}
2023-09-06 14:24:37.217 | INFO     | __main__:evaluate:373 - {'val/clip_val_loss': 0.6975901126861572, 'epoch': 1}
2023-09-06 14:24:37.217 | INFO     | __main__:evaluate:373 - {'val/epoch': 1, 'epoch': 1}
2023-09-06 14:24:37.217 | INFO     | __main__:evaluate:373 - {'val/num_samples': 4, 'epoch': 1}
2023-09-06 14:24:37.217 | INFO     | __main__:evaluate:373 - {'val/val_generative_loss': 6.2071356773376465, 'epoch': 1}
2023-09-06 14:24:46.775 | INFO     | __main__:main:513 - Start epoch 1
2023-09-06 14:24:50.721 | INFO     | __main__:evaluate:338 - Eval Epoch: 2 [2 / 4]	Clip Loss: 0.706215	
2023-09-06 14:24:50.722 | INFO     | __main__:evaluate:345 - Generative Loss: 14.035668	
2023-09-06 14:24:50.811 | INFO     | __main__:evaluate:367 - Eval Epoch: 2 image_to_text_mean_rank: 2.5000	image_to_text_median_rank: 2.0000	image_to_text_R@1: 0.2500	image_to_text_R@5: 1.0000	image_to_text_R@10: 1.0000	text_to_image_mean_rank: 2.2500	text_to_image_median_rank: 2.0000	text_to_image_R@1: 0.2500	text_to_image_R@5: 1.0000	text_to_image_R@10: 1.0000	clip_val_loss: 0.7069	epoch: 2.0000	num_samples: 4.0000	val_generative_loss: 7.0178
2023-09-06 14:24:50.811 | INFO     | __main__:evaluate:373 - {'val/image_to_text_mean_rank': 2.5, 'epoch': 2}
2023-09-06 14:24:50.812 | INFO     | __main__:evaluate:373 - {'val/image_to_text_median_rank': 2.0, 'epoch': 2}
2023-09-06 14:24:50.812 | INFO     | __main__:evaluate:373 - {'val/image_to_text_R@1': 0.25, 'epoch': 2}
2023-09-06 14:24:50.812 | INFO     | __main__:evaluate:373 - {'val/image_to_text_R@5': 1.0, 'epoch': 2}
2023-09-06 14:24:50.812 | INFO     | __main__:evaluate:373 - {'val/image_to_text_R@10': 1.0, 'epoch': 2}
2023-09-06 14:24:50.812 | INFO     | __main__:evaluate:373 - {'val/text_to_image_mean_rank': 2.25, 'epoch': 2}
2023-09-06 14:24:50.812 | INFO     | __main__:evaluate:373 - {'val/text_to_image_median_rank': 2.0, 'epoch': 2}
2023-09-06 14:24:50.812 | INFO     | __main__:evaluate:373 - {'val/text_to_image_R@1': 0.25, 'epoch': 2}
2023-09-06 14:24:50.812 | INFO     | __main__:evaluate:373 - {'val/text_to_image_R@5': 1.0, 'epoch': 2}
2023-09-06 14:24:50.812 | INFO     | __main__:evaluate:373 - {'val/text_to_image_R@10': 1.0, 'epoch': 2}
2023-09-06 14:24:50.812 | INFO     | __main__:evaluate:373 - {'val/clip_val_loss': 0.7068581581115723, 'epoch': 2}
2023-09-06 14:24:50.813 | INFO     | __main__:evaluate:373 - {'val/epoch': 2, 'epoch': 2}
2023-09-06 14:24:50.813 | INFO     | __main__:evaluate:373 - {'val/num_samples': 4, 'epoch': 2}
2023-09-06 14:24:50.813 | INFO     | __main__:evaluate:373 - {'val/val_generative_loss': 7.017834186553955, 'epoch': 2}
2023-09-06 14:24:50.814 | INFO     | __main__:main:513 - Start epoch 2
2023-09-06 14:24:54.701 | INFO     | __main__:evaluate:338 - Eval Epoch: 3 [2 / 4]	Clip Loss: 0.707546	
2023-09-06 14:24:54.701 | INFO     | __main__:evaluate:345 - Generative Loss: 15.064167	
2023-09-06 14:24:54.789 | INFO     | __main__:evaluate:367 - Eval Epoch: 3 image_to_text_mean_rank: 2.5000	image_to_text_median_rank: 2.0000	image_to_text_R@1: 0.2500	image_to_text_R@5: 1.0000	image_to_text_R@10: 1.0000	text_to_image_mean_rank: 2.5000	text_to_image_median_rank: 2.0000	text_to_image_R@1: 0.2500	text_to_image_R@5: 1.0000	text_to_image_R@10: 1.0000	clip_val_loss: 0.6996	epoch: 3.0000	num_samples: 4.0000	val_generative_loss: 7.5321
2023-09-06 14:24:54.789 | INFO     | __main__:evaluate:373 - {'val/image_to_text_mean_rank': 2.5, 'epoch': 3}
2023-09-06 14:24:54.790 | INFO     | __main__:evaluate:373 - {'val/image_to_text_median_rank': 2.0, 'epoch': 3}
2023-09-06 14:24:54.790 | INFO     | __main__:evaluate:373 - {'val/image_to_text_R@1': 0.25, 'epoch': 3}
2023-09-06 14:24:54.790 | INFO     | __main__:evaluate:373 - {'val/image_to_text_R@5': 1.0, 'epoch': 3}
2023-09-06 14:24:54.790 | INFO     | __main__:evaluate:373 - {'val/image_to_text_R@10': 1.0, 'epoch': 3}
2023-09-06 14:24:54.790 | INFO     | __main__:evaluate:373 - {'val/text_to_image_mean_rank': 2.5, 'epoch': 3}
2023-09-06 14:24:54.790 | INFO     | __main__:evaluate:373 - {'val/text_to_image_median_rank': 2.0, 'epoch': 3}
2023-09-06 14:24:54.790 | INFO     | __main__:evaluate:373 - {'val/text_to_image_R@1': 0.25, 'epoch': 3}
2023-09-06 14:24:54.790 | INFO     | __main__:evaluate:373 - {'val/text_to_image_R@5': 1.0, 'epoch': 3}
2023-09-06 14:24:54.790 | INFO     | __main__:evaluate:373 - {'val/text_to_image_R@10': 1.0, 'epoch': 3}
2023-09-06 14:24:54.790 | INFO     | __main__:evaluate:373 - {'val/clip_val_loss': 0.6996469497680664, 'epoch': 3}
2023-09-06 14:24:54.791 | INFO     | __main__:evaluate:373 - {'val/epoch': 3, 'epoch': 3}
2023-09-06 14:24:54.791 | INFO     | __main__:evaluate:373 - {'val/num_samples': 4, 'epoch': 3}
2023-09-06 14:24:54.791 | INFO     | __main__:evaluate:373 - {'val/val_generative_loss': 7.532083511352539, 'epoch': 3}
2023-09-06 14:24:54.792 | INFO     | __main__:main:513 - Start epoch 3
2023-09-06 14:24:58.682 | INFO     | __main__:evaluate:338 - Eval Epoch: 4 [2 / 4]	Clip Loss: 0.699057	
2023-09-06 14:24:58.682 | INFO     | __main__:evaluate:345 - Generative Loss: 16.277431	
2023-09-06 14:24:58.770 | INFO     | __main__:evaluate:367 - Eval Epoch: 4 image_to_text_mean_rank: 2.5000	image_to_text_median_rank: 2.0000	image_to_text_R@1: 0.2500	image_to_text_R@5: 1.0000	image_to_text_R@10: 1.0000	text_to_image_mean_rank: 2.5000	text_to_image_median_rank: 2.0000	text_to_image_R@1: 0.2500	text_to_image_R@5: 1.0000	text_to_image_R@10: 1.0000	clip_val_loss: 0.7055	epoch: 4.0000	num_samples: 4.0000	val_generative_loss: 8.1387
2023-09-06 14:24:58.770 | INFO     | __main__:evaluate:373 - {'val/image_to_text_mean_rank': 2.5, 'epoch': 4}
2023-09-06 14:24:58.771 | INFO     | __main__:evaluate:373 - {'val/image_to_text_median_rank': 2.0, 'epoch': 4}
2023-09-06 14:24:58.771 | INFO     | __main__:evaluate:373 - {'val/image_to_text_R@1': 0.25, 'epoch': 4}
2023-09-06 14:24:58.771 | INFO     | __main__:evaluate:373 - {'val/image_to_text_R@5': 1.0, 'epoch': 4}
2023-09-06 14:24:58.771 | INFO     | __main__:evaluate:373 - {'val/image_to_text_R@10': 1.0, 'epoch': 4}
2023-09-06 14:24:58.771 | INFO     | __main__:evaluate:373 - {'val/text_to_image_mean_rank': 2.5, 'epoch': 4}
2023-09-06 14:24:58.771 | INFO     | __main__:evaluate:373 - {'val/text_to_image_median_rank': 2.0, 'epoch': 4}
2023-09-06 14:24:58.771 | INFO     | __main__:evaluate:373 - {'val/text_to_image_R@1': 0.25, 'epoch': 4}
2023-09-06 14:24:58.771 | INFO     | __main__:evaluate:373 - {'val/text_to_image_R@5': 1.0, 'epoch': 4}
2023-09-06 14:24:58.771 | INFO     | __main__:evaluate:373 - {'val/text_to_image_R@10': 1.0, 'epoch': 4}
2023-09-06 14:24:58.771 | INFO     | __main__:evaluate:373 - {'val/clip_val_loss': 0.7054924368858337, 'epoch': 4}
2023-09-06 14:24:58.771 | INFO     | __main__:evaluate:373 - {'val/epoch': 4, 'epoch': 4}
2023-09-06 14:24:58.772 | INFO     | __main__:evaluate:373 - {'val/num_samples': 4, 'epoch': 4}
2023-09-06 14:24:58.772 | INFO     | __main__:evaluate:373 - {'val/val_generative_loss': 8.138715744018555, 'epoch': 4}
2023-09-06 14:24:58.773 | INFO     | __main__:main:513 - Start epoch 4
2023-09-06 14:25:02.660 | INFO     | __main__:evaluate:338 - Eval Epoch: 5 [2 / 4]	Clip Loss: 0.762120	
2023-09-06 14:25:02.660 | INFO     | __main__:evaluate:345 - Generative Loss: 16.258587	
2023-09-06 14:25:02.749 | INFO     | __main__:evaluate:367 - Eval Epoch: 5 image_to_text_mean_rank: 2.5000	image_to_text_median_rank: 2.0000	image_to_text_R@1: 0.2500	image_to_text_R@5: 1.0000	image_to_text_R@10: 1.0000	text_to_image_mean_rank: 2.5000	text_to_image_median_rank: 2.0000	text_to_image_R@1: 0.2500	text_to_image_R@5: 1.0000	text_to_image_R@10: 1.0000	clip_val_loss: 0.8063	epoch: 5.0000	num_samples: 4.0000	val_generative_loss: 8.1293
2023-09-06 14:25:02.750 | INFO     | __main__:evaluate:373 - {'val/image_to_text_mean_rank': 2.5, 'epoch': 5}
2023-09-06 14:25:02.750 | INFO     | __main__:evaluate:373 - {'val/image_to_text_median_rank': 2.0, 'epoch': 5}
2023-09-06 14:25:02.750 | INFO     | __main__:evaluate:373 - {'val/image_to_text_R@1': 0.25, 'epoch': 5}
2023-09-06 14:25:02.750 | INFO     | __main__:evaluate:373 - {'val/image_to_text_R@5': 1.0, 'epoch': 5}
2023-09-06 14:25:02.750 | INFO     | __main__:evaluate:373 - {'val/image_to_text_R@10': 1.0, 'epoch': 5}
2023-09-06 14:25:02.750 | INFO     | __main__:evaluate:373 - {'val/text_to_image_mean_rank': 2.5, 'epoch': 5}
2023-09-06 14:25:02.750 | INFO     | __main__:evaluate:373 - {'val/text_to_image_median_rank': 2.0, 'epoch': 5}
2023-09-06 14:25:02.750 | INFO     | __main__:evaluate:373 - {'val/text_to_image_R@1': 0.25, 'epoch': 5}
2023-09-06 14:25:02.751 | INFO     | __main__:evaluate:373 - {'val/text_to_image_R@5': 1.0, 'epoch': 5}
2023-09-06 14:25:02.751 | INFO     | __main__:evaluate:373 - {'val/text_to_image_R@10': 1.0, 'epoch': 5}
2023-09-06 14:25:02.751 | INFO     | __main__:evaluate:373 - {'val/clip_val_loss': 0.8062844276428223, 'epoch': 5}
2023-09-06 14:25:02.751 | INFO     | __main__:evaluate:373 - {'val/epoch': 5, 'epoch': 5}
2023-09-06 14:25:02.751 | INFO     | __main__:evaluate:373 - {'val/num_samples': 4, 'epoch': 5}
2023-09-06 14:25:02.751 | INFO     | __main__:evaluate:373 - {'val/val_generative_loss': 8.129293441772461, 'epoch': 5}
2023-09-06 14:25:02.752 | INFO     | __main__:main:513 - Start epoch 5
2023-09-06 14:25:06.634 | INFO     | __main__:evaluate:338 - Eval Epoch: 6 [2 / 4]	Clip Loss: 0.693901	
2023-09-06 14:25:06.634 | INFO     | __main__:evaluate:345 - Generative Loss: 17.237280	
2023-09-06 14:25:06.725 | INFO     | __main__:evaluate:367 - Eval Epoch: 6 image_to_text_mean_rank: 2.5000	image_to_text_median_rank: 2.0000	image_to_text_R@1: 0.2500	image_to_text_R@5: 1.0000	image_to_text_R@10: 1.0000	text_to_image_mean_rank: 2.5000	text_to_image_median_rank: 2.0000	text_to_image_R@1: 0.2500	text_to_image_R@5: 1.0000	text_to_image_R@10: 1.0000	clip_val_loss: 0.6942	epoch: 6.0000	num_samples: 4.0000	val_generative_loss: 8.6186
2023-09-06 14:25:06.726 | INFO     | __main__:evaluate:373 - {'val/image_to_text_mean_rank': 2.5, 'epoch': 6}
2023-09-06 14:25:06.726 | INFO     | __main__:evaluate:373 - {'val/image_to_text_median_rank': 2.0, 'epoch': 6}
2023-09-06 14:25:06.726 | INFO     | __main__:evaluate:373 - {'val/image_to_text_R@1': 0.25, 'epoch': 6}
2023-09-06 14:25:06.726 | INFO     | __main__:evaluate:373 - {'val/image_to_text_R@5': 1.0, 'epoch': 6}
2023-09-06 14:25:06.726 | INFO     | __main__:evaluate:373 - {'val/image_to_text_R@10': 1.0, 'epoch': 6}
2023-09-06 14:25:06.726 | INFO     | __main__:evaluate:373 - {'val/text_to_image_mean_rank': 2.5, 'epoch': 6}
2023-09-06 14:25:06.726 | INFO     | __main__:evaluate:373 - {'val/text_to_image_median_rank': 2.0, 'epoch': 6}
2023-09-06 14:25:06.726 | INFO     | __main__:evaluate:373 - {'val/text_to_image_R@1': 0.25, 'epoch': 6}
2023-09-06 14:25:06.726 | INFO     | __main__:evaluate:373 - {'val/text_to_image_R@5': 1.0, 'epoch': 6}
2023-09-06 14:25:06.726 | INFO     | __main__:evaluate:373 - {'val/text_to_image_R@10': 1.0, 'epoch': 6}
2023-09-06 14:25:06.727 | INFO     | __main__:evaluate:373 - {'val/clip_val_loss': 0.6942057013511658, 'epoch': 6}
2023-09-06 14:25:06.727 | INFO     | __main__:evaluate:373 - {'val/epoch': 6, 'epoch': 6}
2023-09-06 14:25:06.727 | INFO     | __main__:evaluate:373 - {'val/num_samples': 4, 'epoch': 6}
2023-09-06 14:25:06.727 | INFO     | __main__:evaluate:373 - {'val/val_generative_loss': 8.618639945983887, 'epoch': 6}
2023-09-06 14:25:18.771 | INFO     | __main__:inference:424 - Test : [2 / 4]	Clip Loss: 0.693561	
2023-09-06 14:25:18.775 | INFO     | __main__:inference:431 - Generative Loss: 21.115808	
2023-09-06 14:25:18.865 | INFO     | __main__:inference:448 - Test: image_to_text_mean_rank: 2.5000	image_to_text_median_rank: 2.0000	image_to_text_R@1: 0.2500	image_to_text_R@5: 1.0000	image_to_text_R@10: 1.0000	text_to_image_mean_rank: 2.5000	text_to_image_median_rank: 2.0000	text_to_image_R@1: 0.2500	text_to_image_R@5: 1.0000	text_to_image_R@10: 1.0000	clip_test_loss: 0.6936	num_samples: 4.0000	test_generative_loss: 10.5579
2023-09-06 14:25:18.865 | INFO     | __main__:inference:453 - {'test/image_to_text_mean_rank': 2.5}
2023-09-06 14:25:18.865 | INFO     | __main__:inference:453 - {'test/image_to_text_median_rank': 2.0}
2023-09-06 14:25:18.865 | INFO     | __main__:inference:453 - {'test/image_to_text_R@1': 0.25}
2023-09-06 14:25:18.865 | INFO     | __main__:inference:453 - {'test/image_to_text_R@5': 1.0}
2023-09-06 14:25:18.865 | INFO     | __main__:inference:453 - {'test/image_to_text_R@10': 1.0}
2023-09-06 14:25:18.865 | INFO     | __main__:inference:453 - {'test/text_to_image_mean_rank': 2.5}
2023-09-06 14:25:18.866 | INFO     | __main__:inference:453 - {'test/text_to_image_median_rank': 2.0}
2023-09-06 14:25:18.866 | INFO     | __main__:inference:453 - {'test/text_to_image_R@1': 0.25}
2023-09-06 14:25:18.866 | INFO     | __main__:inference:453 - {'test/text_to_image_R@5': 1.0}
2023-09-06 14:25:18.866 | INFO     | __main__:inference:453 - {'test/text_to_image_R@10': 1.0}
2023-09-06 14:25:18.866 | INFO     | __main__:inference:453 - {'test/clip_test_loss': 0.6935547590255737}
2023-09-06 14:25:18.866 | INFO     | __main__:inference:453 - {'test/num_samples': 4}
2023-09-06 14:25:18.866 | INFO     | __main__:inference:453 - {'test/test_generative_loss': 10.557904243469238}
2023-09-06 14:25:18.866 | INFO     | __main__:main:550 - test metric: {'image_to_text_mean_rank': 2.5, 'image_to_text_median_rank': 2.0, 'image_to_text_R@1': 0.25, 'image_to_text_R@5': 1.0, 'image_to_text_R@10': 1.0, 'text_to_image_mean_rank': 2.5, 'text_to_image_median_rank': 2.0, 'text_to_image_R@1': 0.25, 'text_to_image_R@5': 1.0, 'text_to_image_R@10': 1.0, 'clip_test_loss': 0.6935547590255737, 'num_samples': 4, 'test_generative_loss': 10.557904243469238}
