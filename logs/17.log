2023-09-05 17:08:33.092 | INFO     | __main__:main:375 - Namespace(batch_size=2, caption_loss_weight=1.0, checkpoint_dir='checkpoints', contrastive_loss_weight=1.0, dataset='Shanghai_captions', dim=512, dim_head=64, epoch_num=6, heads=8, img_dim=1024, img_encoder='vit', log_every_n_steps=100, logging_dir='logs', lr=0.0003, multimodal_depth=6, num_tokens=20000, pretrained_model='/root/laion-mscoco_finetuned_CoCa-ViT-L-14-laion2B-s13B-b90k/open_clip_pytorch_model.bin', seed=17, test_dataset_ratio=0.1, train_dataset_ratio=0.8, unimodal_depth=6, val_dataset_ratio=0.1, weight_decay=0.01)
2023-09-05 17:08:43.782 | INFO     | __main__:main:385 - model parameters: 638450177
2023-09-05 17:08:43.881 | INFO     | __main__:main:391 - train dataset size: 28
2023-09-05 17:08:43.881 | INFO     | __main__:main:392 - val dataset size: 4
2023-09-05 17:08:43.881 | INFO     | __main__:main:393 - test dataset size: 4
2023-09-05 17:08:43.886 | INFO     | __main__:main:416 - Start epoch 0
2023-09-05 17:08:44.257 | INFO     | __main__:train_one_epoch:180 - Train Epoch: 0 [ 0/28 (7%)] Data (t): 0.001 Batch (t): 0.361, 5.53575/s, Logit Scale: 100.000 Contrastive_loss: 0.69315 (0.69315) Caption_loss: 2.8005 (2.8005) Loss: 3.4937 (3.4937)
2023-09-05 17:08:44.257 | INFO     | __main__:train_one_epoch:200 - {'train/data_time': 0.0009181499481201172, 'step': 0}
2023-09-05 17:08:44.257 | INFO     | __main__:train_one_epoch:200 - {'train/batch_time': 0.36128807067871094, 'step': 0}
2023-09-05 17:08:44.257 | INFO     | __main__:train_one_epoch:200 - {'train/samples_per_second': 5.535748789720144, 'step': 0}
2023-09-05 17:08:44.257 | INFO     | __main__:train_one_epoch:200 - {'train/scale': 100.0, 'step': 0}
2023-09-05 17:08:44.257 | INFO     | __main__:train_one_epoch:200 - {'train/contrastive_loss': 0.6931471824645996, 'step': 0}
2023-09-05 17:08:44.258 | INFO     | __main__:train_one_epoch:200 - {'train/caption_loss': 2.800504684448242, 'step': 0}
2023-09-05 17:08:44.258 | INFO     | __main__:train_one_epoch:200 - {'train/loss': 3.493651866912842, 'step': 0}
2023-09-05 17:08:47.478 | INFO     | __main__:evaluate:253 - Eval Epoch: 1 [2 / 4]	Clip Loss: 0.701728	
2023-09-05 17:08:47.478 | INFO     | __main__:evaluate:259 - Generative Loss: 13.280338	
2023-09-05 17:08:47.555 | INFO     | __main__:evaluate:275 - Eval Epoch: 1 image_to_text_mean_rank: 2.5000	image_to_text_median_rank: 2.0000	image_to_text_R@1: 0.2500	image_to_text_R@5: 1.0000	image_to_text_R@10: 1.0000	text_to_image_mean_rank: 2.5000	text_to_image_median_rank: 2.0000	text_to_image_R@1: 0.2500	text_to_image_R@5: 1.0000	text_to_image_R@10: 1.0000	clip_val_loss: 0.6975	epoch: 1.0000	num_samples: 4.0000	val_generative_loss: 6.6402
2023-09-05 17:08:47.555 | INFO     | __main__:evaluate:281 - {'val/image_to_text_mean_rank': 2.5, 'epoch': 1}
2023-09-05 17:08:47.555 | INFO     | __main__:evaluate:281 - {'val/image_to_text_median_rank': 2.0, 'epoch': 1}
2023-09-05 17:08:47.555 | INFO     | __main__:evaluate:281 - {'val/image_to_text_R@1': 0.25, 'epoch': 1}
2023-09-05 17:08:47.555 | INFO     | __main__:evaluate:281 - {'val/image_to_text_R@5': 1.0, 'epoch': 1}
2023-09-05 17:08:47.556 | INFO     | __main__:evaluate:281 - {'val/image_to_text_R@10': 1.0, 'epoch': 1}
2023-09-05 17:08:47.556 | INFO     | __main__:evaluate:281 - {'val/text_to_image_mean_rank': 2.5, 'epoch': 1}
2023-09-05 17:08:47.556 | INFO     | __main__:evaluate:281 - {'val/text_to_image_median_rank': 2.0, 'epoch': 1}
2023-09-05 17:08:47.556 | INFO     | __main__:evaluate:281 - {'val/text_to_image_R@1': 0.25, 'epoch': 1}
2023-09-05 17:08:47.556 | INFO     | __main__:evaluate:281 - {'val/text_to_image_R@5': 1.0, 'epoch': 1}
2023-09-05 17:08:47.556 | INFO     | __main__:evaluate:281 - {'val/text_to_image_R@10': 1.0, 'epoch': 1}
2023-09-05 17:08:47.556 | INFO     | __main__:evaluate:281 - {'val/clip_val_loss': 0.6974990367889404, 'epoch': 1}
2023-09-05 17:08:47.556 | INFO     | __main__:evaluate:281 - {'val/epoch': 1, 'epoch': 1}
2023-09-05 17:08:47.556 | INFO     | __main__:evaluate:281 - {'val/num_samples': 4, 'epoch': 1}
2023-09-05 17:08:47.556 | INFO     | __main__:evaluate:281 - {'val/val_generative_loss': 6.640169143676758, 'epoch': 1}
2023-09-05 17:08:55.820 | INFO     | __main__:main:416 - Start epoch 1
2023-09-05 17:08:59.279 | INFO     | __main__:evaluate:253 - Eval Epoch: 2 [2 / 4]	Clip Loss: 0.693344	
2023-09-05 17:08:59.279 | INFO     | __main__:evaluate:259 - Generative Loss: 12.890134	
2023-09-05 17:08:59.356 | INFO     | __main__:evaluate:275 - Eval Epoch: 2 image_to_text_mean_rank: 2.5000	image_to_text_median_rank: 2.0000	image_to_text_R@1: 0.2500	image_to_text_R@5: 1.0000	image_to_text_R@10: 1.0000	text_to_image_mean_rank: 2.5000	text_to_image_median_rank: 2.0000	text_to_image_R@1: 0.2500	text_to_image_R@5: 1.0000	text_to_image_R@10: 1.0000	clip_val_loss: 0.6932	epoch: 2.0000	num_samples: 4.0000	val_generative_loss: 6.4451
2023-09-05 17:08:59.356 | INFO     | __main__:evaluate:281 - {'val/image_to_text_mean_rank': 2.5, 'epoch': 2}
2023-09-05 17:08:59.356 | INFO     | __main__:evaluate:281 - {'val/image_to_text_median_rank': 2.0, 'epoch': 2}
2023-09-05 17:08:59.356 | INFO     | __main__:evaluate:281 - {'val/image_to_text_R@1': 0.25, 'epoch': 2}
2023-09-05 17:08:59.356 | INFO     | __main__:evaluate:281 - {'val/image_to_text_R@5': 1.0, 'epoch': 2}
2023-09-05 17:08:59.357 | INFO     | __main__:evaluate:281 - {'val/image_to_text_R@10': 1.0, 'epoch': 2}
2023-09-05 17:08:59.357 | INFO     | __main__:evaluate:281 - {'val/text_to_image_mean_rank': 2.5, 'epoch': 2}
2023-09-05 17:08:59.357 | INFO     | __main__:evaluate:281 - {'val/text_to_image_median_rank': 2.0, 'epoch': 2}
2023-09-05 17:08:59.357 | INFO     | __main__:evaluate:281 - {'val/text_to_image_R@1': 0.25, 'epoch': 2}
2023-09-05 17:08:59.357 | INFO     | __main__:evaluate:281 - {'val/text_to_image_R@5': 1.0, 'epoch': 2}
2023-09-05 17:08:59.357 | INFO     | __main__:evaluate:281 - {'val/text_to_image_R@10': 1.0, 'epoch': 2}
2023-09-05 17:08:59.357 | INFO     | __main__:evaluate:281 - {'val/clip_val_loss': 0.6932037472724915, 'epoch': 2}
2023-09-05 17:08:59.357 | INFO     | __main__:evaluate:281 - {'val/epoch': 2, 'epoch': 2}
2023-09-05 17:08:59.357 | INFO     | __main__:evaluate:281 - {'val/num_samples': 4, 'epoch': 2}
2023-09-05 17:08:59.357 | INFO     | __main__:evaluate:281 - {'val/val_generative_loss': 6.445066928863525, 'epoch': 2}
2023-09-05 17:09:10.402 | INFO     | __main__:main:416 - Start epoch 2
2023-09-05 17:09:14.261 | INFO     | __main__:evaluate:253 - Eval Epoch: 3 [2 / 4]	Clip Loss: 1.030935	
2023-09-05 17:09:14.262 | INFO     | __main__:evaluate:259 - Generative Loss: 12.342090	
2023-09-05 17:09:14.356 | INFO     | __main__:evaluate:275 - Eval Epoch: 3 image_to_text_mean_rank: 2.5000	image_to_text_median_rank: 2.0000	image_to_text_R@1: 0.2500	image_to_text_R@5: 1.0000	image_to_text_R@10: 1.0000	text_to_image_mean_rank: 2.5000	text_to_image_median_rank: 2.0000	text_to_image_R@1: 0.2500	text_to_image_R@5: 1.0000	text_to_image_R@10: 1.0000	clip_val_loss: 0.8646	epoch: 3.0000	num_samples: 4.0000	val_generative_loss: 6.1710
2023-09-05 17:09:14.356 | INFO     | __main__:evaluate:281 - {'val/image_to_text_mean_rank': 2.5, 'epoch': 3}
2023-09-05 17:09:14.356 | INFO     | __main__:evaluate:281 - {'val/image_to_text_median_rank': 2.0, 'epoch': 3}
2023-09-05 17:09:14.356 | INFO     | __main__:evaluate:281 - {'val/image_to_text_R@1': 0.25, 'epoch': 3}
2023-09-05 17:09:14.356 | INFO     | __main__:evaluate:281 - {'val/image_to_text_R@5': 1.0, 'epoch': 3}
2023-09-05 17:09:14.356 | INFO     | __main__:evaluate:281 - {'val/image_to_text_R@10': 1.0, 'epoch': 3}
2023-09-05 17:09:14.357 | INFO     | __main__:evaluate:281 - {'val/text_to_image_mean_rank': 2.5, 'epoch': 3}
2023-09-05 17:09:14.357 | INFO     | __main__:evaluate:281 - {'val/text_to_image_median_rank': 2.0, 'epoch': 3}
2023-09-05 17:09:14.357 | INFO     | __main__:evaluate:281 - {'val/text_to_image_R@1': 0.25, 'epoch': 3}
2023-09-05 17:09:14.357 | INFO     | __main__:evaluate:281 - {'val/text_to_image_R@5': 1.0, 'epoch': 3}
2023-09-05 17:09:14.357 | INFO     | __main__:evaluate:281 - {'val/text_to_image_R@10': 1.0, 'epoch': 3}
2023-09-05 17:09:14.357 | INFO     | __main__:evaluate:281 - {'val/clip_val_loss': 0.8645983338356018, 'epoch': 3}
2023-09-05 17:09:14.357 | INFO     | __main__:evaluate:281 - {'val/epoch': 3, 'epoch': 3}
2023-09-05 17:09:14.357 | INFO     | __main__:evaluate:281 - {'val/num_samples': 4, 'epoch': 3}
2023-09-05 17:09:14.357 | INFO     | __main__:evaluate:281 - {'val/val_generative_loss': 6.171044826507568, 'epoch': 3}
2023-09-05 17:09:14.364 | INFO     | __main__:main:416 - Start epoch 3
2023-09-05 17:09:18.200 | INFO     | __main__:evaluate:253 - Eval Epoch: 4 [2 / 4]	Clip Loss: 0.693326	
2023-09-05 17:09:18.201 | INFO     | __main__:evaluate:259 - Generative Loss: 14.176835	
2023-09-05 17:09:18.294 | INFO     | __main__:evaluate:275 - Eval Epoch: 4 image_to_text_mean_rank: 2.5000	image_to_text_median_rank: 2.0000	image_to_text_R@1: 0.2500	image_to_text_R@5: 1.0000	image_to_text_R@10: 1.0000	text_to_image_mean_rank: 2.5000	text_to_image_median_rank: 2.0000	text_to_image_R@1: 0.2500	text_to_image_R@5: 1.0000	text_to_image_R@10: 1.0000	clip_val_loss: 0.6931	epoch: 4.0000	num_samples: 4.0000	val_generative_loss: 7.0884
2023-09-05 17:09:18.295 | INFO     | __main__:evaluate:281 - {'val/image_to_text_mean_rank': 2.5, 'epoch': 4}
2023-09-05 17:09:18.295 | INFO     | __main__:evaluate:281 - {'val/image_to_text_median_rank': 2.0, 'epoch': 4}
2023-09-05 17:09:18.295 | INFO     | __main__:evaluate:281 - {'val/image_to_text_R@1': 0.25, 'epoch': 4}
2023-09-05 17:09:18.295 | INFO     | __main__:evaluate:281 - {'val/image_to_text_R@5': 1.0, 'epoch': 4}
2023-09-05 17:09:18.295 | INFO     | __main__:evaluate:281 - {'val/image_to_text_R@10': 1.0, 'epoch': 4}
2023-09-05 17:09:18.295 | INFO     | __main__:evaluate:281 - {'val/text_to_image_mean_rank': 2.5, 'epoch': 4}
2023-09-05 17:09:18.295 | INFO     | __main__:evaluate:281 - {'val/text_to_image_median_rank': 2.0, 'epoch': 4}
2023-09-05 17:09:18.296 | INFO     | __main__:evaluate:281 - {'val/text_to_image_R@1': 0.25, 'epoch': 4}
2023-09-05 17:09:18.296 | INFO     | __main__:evaluate:281 - {'val/text_to_image_R@5': 1.0, 'epoch': 4}
2023-09-05 17:09:18.296 | INFO     | __main__:evaluate:281 - {'val/text_to_image_R@10': 1.0, 'epoch': 4}
2023-09-05 17:09:18.296 | INFO     | __main__:evaluate:281 - {'val/clip_val_loss': 0.6931288242340088, 'epoch': 4}
2023-09-05 17:09:18.296 | INFO     | __main__:evaluate:281 - {'val/epoch': 4, 'epoch': 4}
2023-09-05 17:09:18.296 | INFO     | __main__:evaluate:281 - {'val/num_samples': 4, 'epoch': 4}
2023-09-05 17:09:18.296 | INFO     | __main__:evaluate:281 - {'val/val_generative_loss': 7.0884175300598145, 'epoch': 4}
2023-09-05 17:09:26.970 | INFO     | __main__:main:416 - Start epoch 4
2023-09-05 17:09:30.432 | INFO     | __main__:evaluate:253 - Eval Epoch: 5 [2 / 4]	Clip Loss: 0.740197	
2023-09-05 17:09:30.432 | INFO     | __main__:evaluate:259 - Generative Loss: 16.999475	
2023-09-05 17:09:30.509 | INFO     | __main__:evaluate:275 - Eval Epoch: 5 image_to_text_mean_rank: 2.5000	image_to_text_median_rank: 2.0000	image_to_text_R@1: 0.2500	image_to_text_R@5: 1.0000	image_to_text_R@10: 1.0000	text_to_image_mean_rank: 2.5000	text_to_image_median_rank: 2.0000	text_to_image_R@1: 0.2500	text_to_image_R@5: 1.0000	text_to_image_R@10: 1.0000	clip_val_loss: 0.7409	epoch: 5.0000	num_samples: 4.0000	val_generative_loss: 8.4997
2023-09-05 17:09:30.509 | INFO     | __main__:evaluate:281 - {'val/image_to_text_mean_rank': 2.5, 'epoch': 5}
2023-09-05 17:09:30.509 | INFO     | __main__:evaluate:281 - {'val/image_to_text_median_rank': 2.0, 'epoch': 5}
2023-09-05 17:09:30.509 | INFO     | __main__:evaluate:281 - {'val/image_to_text_R@1': 0.25, 'epoch': 5}
2023-09-05 17:09:30.509 | INFO     | __main__:evaluate:281 - {'val/image_to_text_R@5': 1.0, 'epoch': 5}
2023-09-05 17:09:30.509 | INFO     | __main__:evaluate:281 - {'val/image_to_text_R@10': 1.0, 'epoch': 5}
2023-09-05 17:09:30.509 | INFO     | __main__:evaluate:281 - {'val/text_to_image_mean_rank': 2.5, 'epoch': 5}
2023-09-05 17:09:30.509 | INFO     | __main__:evaluate:281 - {'val/text_to_image_median_rank': 2.0, 'epoch': 5}
2023-09-05 17:09:30.509 | INFO     | __main__:evaluate:281 - {'val/text_to_image_R@1': 0.25, 'epoch': 5}
2023-09-05 17:09:30.509 | INFO     | __main__:evaluate:281 - {'val/text_to_image_R@5': 1.0, 'epoch': 5}
2023-09-05 17:09:30.509 | INFO     | __main__:evaluate:281 - {'val/text_to_image_R@10': 1.0, 'epoch': 5}
2023-09-05 17:09:30.509 | INFO     | __main__:evaluate:281 - {'val/clip_val_loss': 0.7409191131591797, 'epoch': 5}
2023-09-05 17:09:30.510 | INFO     | __main__:evaluate:281 - {'val/epoch': 5, 'epoch': 5}
2023-09-05 17:09:30.510 | INFO     | __main__:evaluate:281 - {'val/num_samples': 4, 'epoch': 5}
2023-09-05 17:09:30.510 | INFO     | __main__:evaluate:281 - {'val/val_generative_loss': 8.499737739562988, 'epoch': 5}
2023-09-05 17:09:30.514 | INFO     | __main__:main:416 - Start epoch 5
2023-09-05 17:09:33.953 | INFO     | __main__:evaluate:253 - Eval Epoch: 6 [2 / 4]	Clip Loss: 0.701716	
2023-09-05 17:09:33.953 | INFO     | __main__:evaluate:259 - Generative Loss: 18.732187	
2023-09-05 17:09:34.030 | INFO     | __main__:evaluate:275 - Eval Epoch: 6 image_to_text_mean_rank: 2.5000	image_to_text_median_rank: 2.0000	image_to_text_R@1: 0.2500	image_to_text_R@5: 1.0000	image_to_text_R@10: 1.0000	text_to_image_mean_rank: 2.5000	text_to_image_median_rank: 2.0000	text_to_image_R@1: 0.2500	text_to_image_R@5: 1.0000	text_to_image_R@10: 1.0000	clip_val_loss: 0.6975	epoch: 6.0000	num_samples: 4.0000	val_generative_loss: 9.3661
2023-09-05 17:09:34.030 | INFO     | __main__:evaluate:281 - {'val/image_to_text_mean_rank': 2.5, 'epoch': 6}
2023-09-05 17:09:34.030 | INFO     | __main__:evaluate:281 - {'val/image_to_text_median_rank': 2.0, 'epoch': 6}
2023-09-05 17:09:34.030 | INFO     | __main__:evaluate:281 - {'val/image_to_text_R@1': 0.25, 'epoch': 6}
2023-09-05 17:09:34.030 | INFO     | __main__:evaluate:281 - {'val/image_to_text_R@5': 1.0, 'epoch': 6}
2023-09-05 17:09:34.030 | INFO     | __main__:evaluate:281 - {'val/image_to_text_R@10': 1.0, 'epoch': 6}
2023-09-05 17:09:34.030 | INFO     | __main__:evaluate:281 - {'val/text_to_image_mean_rank': 2.5, 'epoch': 6}
2023-09-05 17:09:34.031 | INFO     | __main__:evaluate:281 - {'val/text_to_image_median_rank': 2.0, 'epoch': 6}
2023-09-05 17:09:34.031 | INFO     | __main__:evaluate:281 - {'val/text_to_image_R@1': 0.25, 'epoch': 6}
2023-09-05 17:09:34.031 | INFO     | __main__:evaluate:281 - {'val/text_to_image_R@5': 1.0, 'epoch': 6}
2023-09-05 17:09:34.031 | INFO     | __main__:evaluate:281 - {'val/text_to_image_R@10': 1.0, 'epoch': 6}
2023-09-05 17:09:34.031 | INFO     | __main__:evaluate:281 - {'val/clip_val_loss': 0.6975007057189941, 'epoch': 6}
2023-09-05 17:09:34.031 | INFO     | __main__:evaluate:281 - {'val/epoch': 6, 'epoch': 6}
2023-09-05 17:09:34.031 | INFO     | __main__:evaluate:281 - {'val/num_samples': 4, 'epoch': 6}
2023-09-05 17:09:34.031 | INFO     | __main__:evaluate:281 - {'val/val_generative_loss': 9.366093635559082, 'epoch': 6}
2023-09-05 17:09:38.443 | INFO     | __main__:inference:332 - Test : [2 / 4]	Clip Loss: 0.701327	
2023-09-05 17:09:38.443 | INFO     | __main__:inference:338 - Generative Loss: 13.419970	
2023-09-05 17:09:38.520 | INFO     | __main__:inference:354 - Test: image_to_text_mean_rank: 2.5000	image_to_text_median_rank: 2.0000	image_to_text_R@1: 0.2500	image_to_text_R@5: 1.0000	image_to_text_R@10: 1.0000	text_to_image_mean_rank: 2.5000	text_to_image_median_rank: 2.0000	text_to_image_R@1: 0.2500	text_to_image_R@5: 1.0000	text_to_image_R@10: 1.0000	clip_test_loss: 0.6973	num_samples: 4.0000	test_generative_loss: 6.7100
2023-09-05 17:09:38.520 | INFO     | __main__:inference:360 - {'test/image_to_text_mean_rank': 2.5}
2023-09-05 17:09:38.520 | INFO     | __main__:inference:360 - {'test/image_to_text_median_rank': 2.0}
2023-09-05 17:09:38.520 | INFO     | __main__:inference:360 - {'test/image_to_text_R@1': 0.25}
2023-09-05 17:09:38.520 | INFO     | __main__:inference:360 - {'test/image_to_text_R@5': 1.0}
2023-09-05 17:09:38.520 | INFO     | __main__:inference:360 - {'test/image_to_text_R@10': 1.0}
2023-09-05 17:09:38.520 | INFO     | __main__:inference:360 - {'test/text_to_image_mean_rank': 2.5}
2023-09-05 17:09:38.520 | INFO     | __main__:inference:360 - {'test/text_to_image_median_rank': 2.0}
2023-09-05 17:09:38.521 | INFO     | __main__:inference:360 - {'test/text_to_image_R@1': 0.25}
2023-09-05 17:09:38.521 | INFO     | __main__:inference:360 - {'test/text_to_image_R@5': 1.0}
2023-09-05 17:09:38.521 | INFO     | __main__:inference:360 - {'test/text_to_image_R@10': 1.0}
2023-09-05 17:09:38.521 | INFO     | __main__:inference:360 - {'test/clip_test_loss': 0.6972547173500061}
2023-09-05 17:09:38.521 | INFO     | __main__:inference:360 - {'test/num_samples': 4}
2023-09-05 17:09:38.521 | INFO     | __main__:inference:360 - {'test/test_generative_loss': 6.70998477935791}
2023-09-05 17:09:38.521 | INFO     | __main__:main:445 - test metric: {'image_to_text_mean_rank': 2.5, 'image_to_text_median_rank': 2.0, 'image_to_text_R@1': 0.25, 'image_to_text_R@5': 1.0, 'image_to_text_R@10': 1.0, 'text_to_image_mean_rank': 2.5, 'text_to_image_median_rank': 2.0, 'text_to_image_R@1': 0.25, 'text_to_image_R@5': 1.0, 'text_to_image_R@10': 1.0, 'clip_test_loss': 0.6972547173500061, 'num_samples': 4, 'test_generative_loss': 6.70998477935791}
2023-09-05 17:10:38.793 | INFO     | __main__:main:375 - Namespace(batch_size=2, caption_loss_weight=1.0, checkpoint_dir='checkpoints', contrastive_loss_weight=1.0, dataset='Shanghai_captions', dim=512, dim_head=64, epoch_num=6, heads=8, img_dim=1024, img_encoder='vit', log_every_n_steps=100, logging_dir='logs', lr=0.0003, multimodal_depth=6, num_tokens=20000, pretrained_model='/root/laion-mscoco_finetuned_CoCa-ViT-L-14-laion2B-s13B-b90k/open_clip_pytorch_model.bin', seed=17, test_dataset_ratio=0.1, train_dataset_ratio=0.8, unimodal_depth=6, val_dataset_ratio=0.1, weight_decay=0.01)
2023-09-05 17:10:49.176 | INFO     | __main__:main:385 - model parameters: 638450177
2023-09-05 17:10:49.275 | INFO     | __main__:main:391 - train dataset size: 28
2023-09-05 17:10:49.276 | INFO     | __main__:main:392 - val dataset size: 4
2023-09-05 17:10:49.276 | INFO     | __main__:main:393 - test dataset size: 4
2023-09-05 17:10:49.280 | INFO     | __main__:main:416 - Start epoch 0
2023-09-05 17:10:49.649 | INFO     | __main__:train_one_epoch:180 - Train Epoch: 0 [ 0/28 (7%)] Data (t): 0.001 Batch (t): 0.359, 5.57547/s, Logit Scale: 100.000 Contrastive_loss: 0.69315 (0.69315) Caption_loss: 2.8005 (2.8005) Loss: 3.4937 (3.4937)
2023-09-05 17:10:49.649 | INFO     | __main__:train_one_epoch:200 - {'train/data_time': 0.0009534358978271484, 'step': 0}
2023-09-05 17:10:49.649 | INFO     | __main__:train_one_epoch:200 - {'train/batch_time': 0.35871434211730957, 'step': 0}
2023-09-05 17:10:49.649 | INFO     | __main__:train_one_epoch:200 - {'train/samples_per_second': 5.575467064391711, 'step': 0}
2023-09-05 17:10:49.649 | INFO     | __main__:train_one_epoch:200 - {'train/scale': 100.0, 'step': 0}
2023-09-05 17:10:49.649 | INFO     | __main__:train_one_epoch:200 - {'train/contrastive_loss': 0.6931471824645996, 'step': 0}
2023-09-05 17:10:49.649 | INFO     | __main__:train_one_epoch:200 - {'train/caption_loss': 2.800504684448242, 'step': 0}
2023-09-05 17:10:49.649 | INFO     | __main__:train_one_epoch:200 - {'train/loss': 3.493651866912842, 'step': 0}
2023-09-05 17:10:52.856 | INFO     | __main__:evaluate:253 - Eval Epoch: 1 [2 / 4]	Clip Loss: 0.701728	
2023-09-05 17:10:52.856 | INFO     | __main__:evaluate:259 - Generative Loss: 13.280338	
2023-09-05 17:10:52.933 | INFO     | __main__:evaluate:275 - Eval Epoch: 1 image_to_text_mean_rank: 2.5000	image_to_text_median_rank: 2.0000	image_to_text_R@1: 0.2500	image_to_text_R@5: 1.0000	image_to_text_R@10: 1.0000	text_to_image_mean_rank: 2.5000	text_to_image_median_rank: 2.0000	text_to_image_R@1: 0.2500	text_to_image_R@5: 1.0000	text_to_image_R@10: 1.0000	clip_val_loss: 0.6975	epoch: 1.0000	num_samples: 4.0000	val_generative_loss: 6.6402
2023-09-05 17:10:52.933 | INFO     | __main__:evaluate:281 - {'val/image_to_text_mean_rank': 2.5, 'epoch': 1}
2023-09-05 17:10:52.933 | INFO     | __main__:evaluate:281 - {'val/image_to_text_median_rank': 2.0, 'epoch': 1}
2023-09-05 17:10:52.934 | INFO     | __main__:evaluate:281 - {'val/image_to_text_R@1': 0.25, 'epoch': 1}
2023-09-05 17:10:52.934 | INFO     | __main__:evaluate:281 - {'val/image_to_text_R@5': 1.0, 'epoch': 1}
2023-09-05 17:10:52.934 | INFO     | __main__:evaluate:281 - {'val/image_to_text_R@10': 1.0, 'epoch': 1}
2023-09-05 17:10:52.934 | INFO     | __main__:evaluate:281 - {'val/text_to_image_mean_rank': 2.5, 'epoch': 1}
2023-09-05 17:10:52.934 | INFO     | __main__:evaluate:281 - {'val/text_to_image_median_rank': 2.0, 'epoch': 1}
2023-09-05 17:10:52.934 | INFO     | __main__:evaluate:281 - {'val/text_to_image_R@1': 0.25, 'epoch': 1}
2023-09-05 17:10:52.934 | INFO     | __main__:evaluate:281 - {'val/text_to_image_R@5': 1.0, 'epoch': 1}
2023-09-05 17:10:52.934 | INFO     | __main__:evaluate:281 - {'val/text_to_image_R@10': 1.0, 'epoch': 1}
2023-09-05 17:10:52.934 | INFO     | __main__:evaluate:281 - {'val/clip_val_loss': 0.6974990367889404, 'epoch': 1}
2023-09-05 17:10:52.934 | INFO     | __main__:evaluate:281 - {'val/epoch': 1, 'epoch': 1}
2023-09-05 17:10:52.934 | INFO     | __main__:evaluate:281 - {'val/num_samples': 4, 'epoch': 1}
2023-09-05 17:10:52.934 | INFO     | __main__:evaluate:281 - {'val/val_generative_loss': 6.640169143676758, 'epoch': 1}
2023-09-05 17:11:01.372 | INFO     | __main__:main:416 - Start epoch 1
2023-09-05 17:11:04.834 | INFO     | __main__:evaluate:253 - Eval Epoch: 2 [2 / 4]	Clip Loss: 0.693344	
2023-09-05 17:11:04.834 | INFO     | __main__:evaluate:259 - Generative Loss: 12.890134	
2023-09-05 17:11:04.911 | INFO     | __main__:evaluate:275 - Eval Epoch: 2 image_to_text_mean_rank: 2.5000	image_to_text_median_rank: 2.0000	image_to_text_R@1: 0.2500	image_to_text_R@5: 1.0000	image_to_text_R@10: 1.0000	text_to_image_mean_rank: 2.5000	text_to_image_median_rank: 2.0000	text_to_image_R@1: 0.2500	text_to_image_R@5: 1.0000	text_to_image_R@10: 1.0000	clip_val_loss: 0.6932	epoch: 2.0000	num_samples: 4.0000	val_generative_loss: 6.4451
2023-09-05 17:11:04.911 | INFO     | __main__:evaluate:281 - {'val/image_to_text_mean_rank': 2.5, 'epoch': 2}
2023-09-05 17:11:04.912 | INFO     | __main__:evaluate:281 - {'val/image_to_text_median_rank': 2.0, 'epoch': 2}
2023-09-05 17:11:04.912 | INFO     | __main__:evaluate:281 - {'val/image_to_text_R@1': 0.25, 'epoch': 2}
2023-09-05 17:11:04.912 | INFO     | __main__:evaluate:281 - {'val/image_to_text_R@5': 1.0, 'epoch': 2}
2023-09-05 17:11:04.912 | INFO     | __main__:evaluate:281 - {'val/image_to_text_R@10': 1.0, 'epoch': 2}
2023-09-05 17:11:04.912 | INFO     | __main__:evaluate:281 - {'val/text_to_image_mean_rank': 2.5, 'epoch': 2}
2023-09-05 17:11:04.912 | INFO     | __main__:evaluate:281 - {'val/text_to_image_median_rank': 2.0, 'epoch': 2}
2023-09-05 17:11:04.912 | INFO     | __main__:evaluate:281 - {'val/text_to_image_R@1': 0.25, 'epoch': 2}
2023-09-05 17:11:04.912 | INFO     | __main__:evaluate:281 - {'val/text_to_image_R@5': 1.0, 'epoch': 2}
2023-09-05 17:11:04.912 | INFO     | __main__:evaluate:281 - {'val/text_to_image_R@10': 1.0, 'epoch': 2}
2023-09-05 17:11:04.912 | INFO     | __main__:evaluate:281 - {'val/clip_val_loss': 0.6932037472724915, 'epoch': 2}
2023-09-05 17:11:04.912 | INFO     | __main__:evaluate:281 - {'val/epoch': 2, 'epoch': 2}
2023-09-05 17:11:04.912 | INFO     | __main__:evaluate:281 - {'val/num_samples': 4, 'epoch': 2}
2023-09-05 17:11:04.912 | INFO     | __main__:evaluate:281 - {'val/val_generative_loss': 6.445066928863525, 'epoch': 2}
2023-09-05 17:11:15.952 | INFO     | __main__:main:416 - Start epoch 2
2023-09-05 17:11:19.805 | INFO     | __main__:evaluate:253 - Eval Epoch: 3 [2 / 4]	Clip Loss: 1.030935	
2023-09-05 17:11:19.806 | INFO     | __main__:evaluate:259 - Generative Loss: 12.342090	
2023-09-05 17:11:19.900 | INFO     | __main__:evaluate:275 - Eval Epoch: 3 image_to_text_mean_rank: 2.5000	image_to_text_median_rank: 2.0000	image_to_text_R@1: 0.2500	image_to_text_R@5: 1.0000	image_to_text_R@10: 1.0000	text_to_image_mean_rank: 2.5000	text_to_image_median_rank: 2.0000	text_to_image_R@1: 0.2500	text_to_image_R@5: 1.0000	text_to_image_R@10: 1.0000	clip_val_loss: 0.8646	epoch: 3.0000	num_samples: 4.0000	val_generative_loss: 6.1710
2023-09-05 17:11:19.900 | INFO     | __main__:evaluate:281 - {'val/image_to_text_mean_rank': 2.5, 'epoch': 3}
2023-09-05 17:11:19.900 | INFO     | __main__:evaluate:281 - {'val/image_to_text_median_rank': 2.0, 'epoch': 3}
2023-09-05 17:11:19.900 | INFO     | __main__:evaluate:281 - {'val/image_to_text_R@1': 0.25, 'epoch': 3}
2023-09-05 17:11:19.900 | INFO     | __main__:evaluate:281 - {'val/image_to_text_R@5': 1.0, 'epoch': 3}
2023-09-05 17:11:19.900 | INFO     | __main__:evaluate:281 - {'val/image_to_text_R@10': 1.0, 'epoch': 3}
2023-09-05 17:11:19.901 | INFO     | __main__:evaluate:281 - {'val/text_to_image_mean_rank': 2.5, 'epoch': 3}
2023-09-05 17:11:19.901 | INFO     | __main__:evaluate:281 - {'val/text_to_image_median_rank': 2.0, 'epoch': 3}
2023-09-05 17:11:19.901 | INFO     | __main__:evaluate:281 - {'val/text_to_image_R@1': 0.25, 'epoch': 3}
2023-09-05 17:11:19.901 | INFO     | __main__:evaluate:281 - {'val/text_to_image_R@5': 1.0, 'epoch': 3}
2023-09-05 17:11:19.901 | INFO     | __main__:evaluate:281 - {'val/text_to_image_R@10': 1.0, 'epoch': 3}
2023-09-05 17:11:19.901 | INFO     | __main__:evaluate:281 - {'val/clip_val_loss': 0.8645983338356018, 'epoch': 3}
2023-09-05 17:11:19.901 | INFO     | __main__:evaluate:281 - {'val/epoch': 3, 'epoch': 3}
2023-09-05 17:11:19.901 | INFO     | __main__:evaluate:281 - {'val/num_samples': 4, 'epoch': 3}
2023-09-05 17:11:19.901 | INFO     | __main__:evaluate:281 - {'val/val_generative_loss': 6.171044826507568, 'epoch': 3}
2023-09-05 17:11:19.908 | INFO     | __main__:main:416 - Start epoch 3
2023-09-05 17:11:23.737 | INFO     | __main__:evaluate:253 - Eval Epoch: 4 [2 / 4]	Clip Loss: 0.693326	
2023-09-05 17:11:23.737 | INFO     | __main__:evaluate:259 - Generative Loss: 14.176835	
2023-09-05 17:11:23.831 | INFO     | __main__:evaluate:275 - Eval Epoch: 4 image_to_text_mean_rank: 2.5000	image_to_text_median_rank: 2.0000	image_to_text_R@1: 0.2500	image_to_text_R@5: 1.0000	image_to_text_R@10: 1.0000	text_to_image_mean_rank: 2.5000	text_to_image_median_rank: 2.0000	text_to_image_R@1: 0.2500	text_to_image_R@5: 1.0000	text_to_image_R@10: 1.0000	clip_val_loss: 0.6931	epoch: 4.0000	num_samples: 4.0000	val_generative_loss: 7.0884
2023-09-05 17:11:23.832 | INFO     | __main__:evaluate:281 - {'val/image_to_text_mean_rank': 2.5, 'epoch': 4}
2023-09-05 17:11:23.832 | INFO     | __main__:evaluate:281 - {'val/image_to_text_median_rank': 2.0, 'epoch': 4}
2023-09-05 17:11:23.832 | INFO     | __main__:evaluate:281 - {'val/image_to_text_R@1': 0.25, 'epoch': 4}
2023-09-05 17:11:23.832 | INFO     | __main__:evaluate:281 - {'val/image_to_text_R@5': 1.0, 'epoch': 4}
2023-09-05 17:11:23.832 | INFO     | __main__:evaluate:281 - {'val/image_to_text_R@10': 1.0, 'epoch': 4}
2023-09-05 17:11:23.832 | INFO     | __main__:evaluate:281 - {'val/text_to_image_mean_rank': 2.5, 'epoch': 4}
2023-09-05 17:11:23.832 | INFO     | __main__:evaluate:281 - {'val/text_to_image_median_rank': 2.0, 'epoch': 4}
2023-09-05 17:11:23.832 | INFO     | __main__:evaluate:281 - {'val/text_to_image_R@1': 0.25, 'epoch': 4}
2023-09-05 17:11:23.833 | INFO     | __main__:evaluate:281 - {'val/text_to_image_R@5': 1.0, 'epoch': 4}
2023-09-05 17:11:23.833 | INFO     | __main__:evaluate:281 - {'val/text_to_image_R@10': 1.0, 'epoch': 4}
2023-09-05 17:11:23.833 | INFO     | __main__:evaluate:281 - {'val/clip_val_loss': 0.6931288242340088, 'epoch': 4}
2023-09-05 17:11:23.833 | INFO     | __main__:evaluate:281 - {'val/epoch': 4, 'epoch': 4}
2023-09-05 17:11:23.833 | INFO     | __main__:evaluate:281 - {'val/num_samples': 4, 'epoch': 4}
2023-09-05 17:11:23.833 | INFO     | __main__:evaluate:281 - {'val/val_generative_loss': 7.0884175300598145, 'epoch': 4}
2023-09-05 17:11:32.497 | INFO     | __main__:main:416 - Start epoch 4
2023-09-05 17:11:36.285 | INFO     | __main__:evaluate:253 - Eval Epoch: 5 [2 / 4]	Clip Loss: 0.740197	
2023-09-05 17:11:36.285 | INFO     | __main__:evaluate:259 - Generative Loss: 16.999475	
2023-09-05 17:11:36.383 | INFO     | __main__:evaluate:275 - Eval Epoch: 5 image_to_text_mean_rank: 2.5000	image_to_text_median_rank: 2.0000	image_to_text_R@1: 0.2500	image_to_text_R@5: 1.0000	image_to_text_R@10: 1.0000	text_to_image_mean_rank: 2.5000	text_to_image_median_rank: 2.0000	text_to_image_R@1: 0.2500	text_to_image_R@5: 1.0000	text_to_image_R@10: 1.0000	clip_val_loss: 0.7409	epoch: 5.0000	num_samples: 4.0000	val_generative_loss: 8.4997
2023-09-05 17:11:36.383 | INFO     | __main__:evaluate:281 - {'val/image_to_text_mean_rank': 2.5, 'epoch': 5}
2023-09-05 17:11:36.384 | INFO     | __main__:evaluate:281 - {'val/image_to_text_median_rank': 2.0, 'epoch': 5}
2023-09-05 17:11:36.384 | INFO     | __main__:evaluate:281 - {'val/image_to_text_R@1': 0.25, 'epoch': 5}
2023-09-05 17:11:36.384 | INFO     | __main__:evaluate:281 - {'val/image_to_text_R@5': 1.0, 'epoch': 5}
2023-09-05 17:11:36.384 | INFO     | __main__:evaluate:281 - {'val/image_to_text_R@10': 1.0, 'epoch': 5}
2023-09-05 17:11:36.384 | INFO     | __main__:evaluate:281 - {'val/text_to_image_mean_rank': 2.5, 'epoch': 5}
2023-09-05 17:11:36.384 | INFO     | __main__:evaluate:281 - {'val/text_to_image_median_rank': 2.0, 'epoch': 5}
2023-09-05 17:11:36.384 | INFO     | __main__:evaluate:281 - {'val/text_to_image_R@1': 0.25, 'epoch': 5}
2023-09-05 17:11:36.384 | INFO     | __main__:evaluate:281 - {'val/text_to_image_R@5': 1.0, 'epoch': 5}
2023-09-05 17:11:36.385 | INFO     | __main__:evaluate:281 - {'val/text_to_image_R@10': 1.0, 'epoch': 5}
2023-09-05 17:11:36.385 | INFO     | __main__:evaluate:281 - {'val/clip_val_loss': 0.7409191131591797, 'epoch': 5}
2023-09-05 17:11:36.385 | INFO     | __main__:evaluate:281 - {'val/epoch': 5, 'epoch': 5}
2023-09-05 17:11:36.385 | INFO     | __main__:evaluate:281 - {'val/num_samples': 4, 'epoch': 5}
2023-09-05 17:11:36.385 | INFO     | __main__:evaluate:281 - {'val/val_generative_loss': 8.499737739562988, 'epoch': 5}
2023-09-05 17:11:36.392 | INFO     | __main__:main:416 - Start epoch 5
2023-09-05 17:11:39.875 | INFO     | __main__:evaluate:253 - Eval Epoch: 6 [2 / 4]	Clip Loss: 0.701716	
2023-09-05 17:11:39.876 | INFO     | __main__:evaluate:259 - Generative Loss: 18.732187	
2023-09-05 17:11:39.954 | INFO     | __main__:evaluate:275 - Eval Epoch: 6 image_to_text_mean_rank: 2.5000	image_to_text_median_rank: 2.0000	image_to_text_R@1: 0.2500	image_to_text_R@5: 1.0000	image_to_text_R@10: 1.0000	text_to_image_mean_rank: 2.5000	text_to_image_median_rank: 2.0000	text_to_image_R@1: 0.2500	text_to_image_R@5: 1.0000	text_to_image_R@10: 1.0000	clip_val_loss: 0.6975	epoch: 6.0000	num_samples: 4.0000	val_generative_loss: 9.3661
2023-09-05 17:11:39.954 | INFO     | __main__:evaluate:281 - {'val/image_to_text_mean_rank': 2.5, 'epoch': 6}
2023-09-05 17:11:39.954 | INFO     | __main__:evaluate:281 - {'val/image_to_text_median_rank': 2.0, 'epoch': 6}
2023-09-05 17:11:39.954 | INFO     | __main__:evaluate:281 - {'val/image_to_text_R@1': 0.25, 'epoch': 6}
2023-09-05 17:11:39.954 | INFO     | __main__:evaluate:281 - {'val/image_to_text_R@5': 1.0, 'epoch': 6}
2023-09-05 17:11:39.954 | INFO     | __main__:evaluate:281 - {'val/image_to_text_R@10': 1.0, 'epoch': 6}
2023-09-05 17:11:39.954 | INFO     | __main__:evaluate:281 - {'val/text_to_image_mean_rank': 2.5, 'epoch': 6}
2023-09-05 17:11:39.954 | INFO     | __main__:evaluate:281 - {'val/text_to_image_median_rank': 2.0, 'epoch': 6}
2023-09-05 17:11:39.954 | INFO     | __main__:evaluate:281 - {'val/text_to_image_R@1': 0.25, 'epoch': 6}
2023-09-05 17:11:39.954 | INFO     | __main__:evaluate:281 - {'val/text_to_image_R@5': 1.0, 'epoch': 6}
2023-09-05 17:11:39.954 | INFO     | __main__:evaluate:281 - {'val/text_to_image_R@10': 1.0, 'epoch': 6}
2023-09-05 17:11:39.954 | INFO     | __main__:evaluate:281 - {'val/clip_val_loss': 0.6975007057189941, 'epoch': 6}
2023-09-05 17:11:39.955 | INFO     | __main__:evaluate:281 - {'val/epoch': 6, 'epoch': 6}
2023-09-05 17:11:39.955 | INFO     | __main__:evaluate:281 - {'val/num_samples': 4, 'epoch': 6}
2023-09-05 17:11:39.955 | INFO     | __main__:evaluate:281 - {'val/val_generative_loss': 9.366093635559082, 'epoch': 6}
2023-09-05 17:11:44.481 | INFO     | __main__:inference:332 - Test : [2 / 4]	Clip Loss: 0.701327	
2023-09-05 17:11:44.481 | INFO     | __main__:inference:338 - Generative Loss: 13.419970	
2023-09-05 17:11:44.566 | INFO     | __main__:inference:354 - Test: image_to_text_mean_rank: 2.5000	image_to_text_median_rank: 2.0000	image_to_text_R@1: 0.2500	image_to_text_R@5: 1.0000	image_to_text_R@10: 1.0000	text_to_image_mean_rank: 2.5000	text_to_image_median_rank: 2.0000	text_to_image_R@1: 0.2500	text_to_image_R@5: 1.0000	text_to_image_R@10: 1.0000	clip_test_loss: 0.6973	num_samples: 4.0000	test_generative_loss: 6.7100
2023-09-05 17:11:44.566 | INFO     | __main__:inference:360 - {'test/image_to_text_mean_rank': 2.5}
2023-09-05 17:11:44.567 | INFO     | __main__:inference:360 - {'test/image_to_text_median_rank': 2.0}
2023-09-05 17:11:44.567 | INFO     | __main__:inference:360 - {'test/image_to_text_R@1': 0.25}
2023-09-05 17:11:44.567 | INFO     | __main__:inference:360 - {'test/image_to_text_R@5': 1.0}
2023-09-05 17:11:44.567 | INFO     | __main__:inference:360 - {'test/image_to_text_R@10': 1.0}
2023-09-05 17:11:44.567 | INFO     | __main__:inference:360 - {'test/text_to_image_mean_rank': 2.5}
2023-09-05 17:11:44.567 | INFO     | __main__:inference:360 - {'test/text_to_image_median_rank': 2.0}
2023-09-05 17:11:44.567 | INFO     | __main__:inference:360 - {'test/text_to_image_R@1': 0.25}
2023-09-05 17:11:44.567 | INFO     | __main__:inference:360 - {'test/text_to_image_R@5': 1.0}
2023-09-05 17:11:44.567 | INFO     | __main__:inference:360 - {'test/text_to_image_R@10': 1.0}
2023-09-05 17:11:44.567 | INFO     | __main__:inference:360 - {'test/clip_test_loss': 0.6972547173500061}
2023-09-05 17:11:44.567 | INFO     | __main__:inference:360 - {'test/num_samples': 4}
2023-09-05 17:11:44.567 | INFO     | __main__:inference:360 - {'test/test_generative_loss': 6.70998477935791}
2023-09-05 17:11:44.568 | INFO     | __main__:main:445 - test metric: {'image_to_text_mean_rank': 2.5, 'image_to_text_median_rank': 2.0, 'image_to_text_R@1': 0.25, 'image_to_text_R@5': 1.0, 'image_to_text_R@10': 1.0, 'text_to_image_mean_rank': 2.5, 'text_to_image_median_rank': 2.0, 'text_to_image_R@1': 0.25, 'text_to_image_R@5': 1.0, 'text_to_image_R@10': 1.0, 'clip_test_loss': 0.6972547173500061, 'num_samples': 4, 'test_generative_loss': 6.70998477935791}
